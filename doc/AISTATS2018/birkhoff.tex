\documentclass[twoside]{article}

\input{preamble.tex}
\input{preamble_math.tex}
\input{preamble_acronyms.tex}

\usepackage{blindtext}

\usepackage{aistats2018}

\DeclareRobustCommand{\parhead}[1]{\textbf{#1}~}

% If your paper is accepted, change the options for the package
% aistats2018 as follows:
%
%\usepackage[accepted]{aistats2018}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.


\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Reparameterizing the Birkhoff Polytope for \\
  Variational Permutation Inference}

% \aistatsauthor{ Gonzalo E. Mena$^*$ \And Scott W. Linderman$^*$
%   \And  Hal Cooper \AND Liam Paninski \And John P. Cunningham }

% \aistatsaddress{ Columbia University}

\aistatsauthor{ Anonymous Authors }

\aistatsaddress{ Anonymous Institutions}
]

% \begin{abstract}
%   How can we efficiently perform posterior inference over the space
%   of permutations when there are~$N!$ permutations of a set of~$N$
%   elements?  Clearly, estimating a complete probability mass function
%   over this space quicky becomes intractable as~$N$ grows. Our goal is
%   to derive a tractable algorithm for performing approximate inference
%   over this challenging discrete space.  To that end, we consider
%   extensions of the recently proposed Gumbel-softmax method, which
%   leverages continuous relaxations to perform discrete variational
%   inference with reparameterization gradients. While the
%   Gumbel-softmax method is not immediately applicable to permutation
%   inference, we show that two alternative reparameterizations are both
%   comparable to Gumbel-softmax on tractable discrete problems and
%   easily extensible to permutation inference. Specifically, we develop
%   continuous relaxations of permutation matrices to matrices that are
%   either exactly or nearly doubly stochastic, i.e. to points either in
%   or near the Birkhoff polytope.  We then derive invertible and
%   differentiable maps from densities on unconstrained space to
%   densities on or near the Birkhoff polytope. These transformations
%   are parameterized by a ``temperature'' that controls how
%   concentrated the resulting density is at the extrema of the Birkhoff
%   polytope; i.e. at permutation matrices.  This relaxation admits
%   variational inference via stochastic gradient ascent over the
%   distributions on doubly stochastic matrices (and in the
%   zero-temperature limit, on permutation matrices) using Monte Carlo
%   estimates of the reparameterized gradient.
% \end{abstract}

% Take 2 -- significantly shorter
\begin{abstract}
  How can we efficiently perform posterior inference over the space of
  permutations when there are~$N!$ permutations of a set of~$N$
  elements?  Combinatorial optimization algorithms may enable
  efficient point estimation, but fully Bayesian inference poses a
  severe challenge in this high-dimensional, discrete space.  We begin
  with a common maneuver: we relax the discrete set of permutation
  matrices---the vertices of the Birkhoff polytope---to the continuous
  set of doubly-stochastic matrices---the interior of the polytope.
  Our primary contribution is a pair of invertible and differentiable
  maps from densities on unconstrained space to densities on or near
  the Birkhoff polytope. These transformations are parameterized by a
  ``temperature'' that controls how concentrated the resulting density
  is at the extrema of the Birkhoff polytope; i.e. at permutation
  matrices.  With these transformations, we perform variational
  inference over distributions on doubly stochastic matrices (and in
  the zero-temperature limit, on permutation matrices), leveraging
  reparameterization gradients to guide our optimization.
\end{abstract}


\section{Introduction}

% Permutation inference central to many machine learning problems
% - Matching problems
% - Multiple object tracking
% - Ranking
% - As latent step in a generative model
Permutation inference is central to many modern machine learning
problems.  Identity management ~\citep{guibas2008identity} and
multiple-object tracking~\citep{shin2005lazy, kondor2007multi} are
fundamentally concerned with finding a permutation that maps an
observed set of items to a set of canonical labels.
Ranking problems, critical to search and recommender systems, require
inference over the space of item orderings \citep{meilua2007consensus,
  lebanon2008non, adams2011ranking}.  Moreover, many probabilistic models, like
preferential attachment network models~\citep{bloem2016random} and
repulsive point process models~\citep{rao2016bayesian}, incorporate a
latent permutation into their generative processes; inference over
model parameters requires integrating over the set of permutations
that could have given rise to the observed data.  In many of these
settings, permutation inference is just one component of a larger
estimation problem involving unknown model parameters and hierarchical
structure.

% Emphasize the importance of Bayesian approach and recent advances
% in variational inference
The task of computing optimal point estimates of permutations under
various loss functions has been well studied in the combinatorial
optimization literature ~\citep{kuhn1955hungarian,
  munkres1957algorithms, lawler1963quadratic}. However, many
probabilistic tasks require reasoning about uncertainty regarding
permutation matrices.  A variety of Bayesian permutation inference
algorithms have been proposed, leveraging sampling methods
\citep{diaconis1988group, miller2013exact, harrison2013importance},
Fourier representations~\citep{kondor2007multi, huang2009fourier}, as
well as convex~\citep{lim2014beyond} and
continuous~\citep{plis2011directional} relaxations for approximating
the posterior distribution.  Here, we address this problem from an
alternative direction, leveraging stochastic variational
inference~\citep{hoffman2013stochastic} and reparameterization
gradients~\citep{rezende2014stochastic, Kingma2014} to derive a
scalable and efficient permutation inference algorithm.

% Paper structure
Section~\ref{sec:background} lays the necessary groundwork,
introducing definitions, prior work on permutation inference, variational
inference, and continuous relaxations.  Section~\ref{sec:permutation}
presents our primary contribution: a pair of transformations that
enable variational inference over doubly-stochastic matrices, and, in
the zero-temperature limit, permutations, via stochastic variational
inference.  In the process, we show how these transformations connect
to recent work on discrete variational
inference~\citep{maddison2016concrete, jang2016categorical}.
Section~\ref{sec:results} presents a variety of experiments that
illustrate the benefits of the proposed variational approach.
  
\section{Background}
\label{sec:background}

% We begin with definitions and notation, a review of
% variational inference and the reparameterization trick, and a
% discussion related work.

\subsection{Definitions and notation.}  A permutation is a bijective
mapping of a set~$\mcX$ onto itself.
When~${\mcX = \{x_1, \ldots, x_N\}}$, this mapping is conveniently
represented as a binary matrix~${X \in \{0,1\}^{N \times N}}$
where~${X_{m,n}=1}$ implies that~$x_m$ is mapped to~$x_n$.  Since
permutations are bijections, both the rows and columns of~$X$ must
sum to one.  From a geometric perspective, the Birkhoff-von Neumann
theorem states that permutation matrices are vertices of the convex
hull of doubly stochastic matrices; i.e. non-negative square matrices
whose rows and columns sum to one. The set of doubly
stochastic matrices is known as the \emph{Birkhoff polytope}, and it
is defined by,
\begin{align*}
  \mcB_N = \Big \{X : \qquad 
           X_{m,n} &\geq 0   & &\forall \, m,n \in 1, \ldots, N; \\
           \sum_{n=1}^N X_{m,n} &= 1  & &\forall \, m \in 1, \ldots, N; \\
           \sum_{m=1}^N X_{m,n} & =1 &  &\forall \, n \in 1, \ldots, N \Big\}.
\end{align*}
These linear row- and column-normalization constraints
restrict~$\mcB_N$ to a~${(N-1)^2}$ dimensional subset
of~$\reals^{N \times N}$.  Despite these constraints, we have a number
of efficient algorithms for working with these objects.
\emph{Sinkhorn propagation}~\citep{sinkhorn1967concerning} projects the
positive orthant onto~$\mcB_N$ by iteratively normalizing the rows and
columns, and the \emph{Hungarian algorithm}~\citep{kuhn1955hungarian,
  munkres1957algorithms} solves the minimum weight bipartite matching
problem---optimizing a linear objective over the set of permutation
matrices---in cubic time.





\subsection{Variational inference and the reparameterization trick}
Variational Bayesian inference algorithms aim to approximate the
posterior distribution~$p(x \given y)$ with a more tractable
distribution~$q(x; \theta)$, where ``tractable'' means that, at a
minimum, we can sample~$q$ and evaluate it pointwise (including
its normalization constant).  We find this approximate distribution
by searching for the parameters~$\theta$ that minimize the Kullback-Leibler (KL)
divergence between~$q$ and the true posterior, or equivalently,
maximize the evidence lower bound (ELBO),
\begin{align*}
  \mcL(\theta) &\triangleq \bbE_q \left[ \log p(x, y) - \log q(x; \theta) \right].
\end{align*}
Perhaps the simplest method of optimizing the ELBO is stochastic
gradient ascent. 
However, computing~$\nabla_\theta \mcL(\theta)$ requires some care
since the ELBO contains an expectation with respect to a distribution
that depends on these parameters.

When~$x$ is a continuous random variable, we can often go one step
further and leverage the \emph{reparameterization trick}
\citep{Salimans2013, Kingma2014}.  Specifically, in some cases we can
simulate from~$q$ via the following equivalence,
\begin{align*}
  x &\sim q(x; \theta)
      & \iff & &  
  \xi &\sim r(\xi), \quad x = g(\theta, \xi),
\end{align*}
where~$r$ is a distribution on the ``noise''~$\xi$ and
where~$g(\xi; \theta)$ is a deterministic and differentiable
function. For example,
if~${q(x; \theta) = \mathcal{N}(x \given \theta, 1)}$, we can
reparameterize by setting the noise distribution
to~${r(\xi) = \mathcal{N}(\xi \given 0, 1)}$ and using the
transformation~${g(\xi; \theta) = \xi + \theta}$.  The
reparameterization trick effectively ``factors out'' the randomness
of~$q$. With this transformation, we can bring the gradient inside the
expectation as follows,
\begin{multline}
  \label{eq:elbo}
  \nabla_\theta \mcL(\theta) 
  = \E_{r(\xi)} \Big[ \nabla_\theta \log p(g(\xi; \theta) \given y) \\
    - \nabla_\theta  \log q(g(\xi; \theta); \theta) \Big].
\end{multline}
This gradient can be estimated with Monte Carlo, and, in practice,
this leads to lower variance estimates of the gradient than, for
example, the score function estimator \citep{Williams1992, Glynn1990}.
However, for $g$ to be differentiable $x$ needs to be continuous.


% % Gumbel-softmax motivation
% Continuous relaxations underlie many approximate algorithms for
% discrete optimization and inference.  After relaxation, we can
% capitalize on local gradients and curvature information. Indeed, this
% is the motivation for the recently proposed Gumbel-softmax method for
% discrete variational inference~\citep{jang2016categorical,
%   maddison2016concrete}.  It is based on the following observation:
% categorical distributions may be viewed as atomic densities
% on the vertices of the simplex; by relaxing this to a continuous
% density on the interior of the simplex we can approximate the discrete
% inference problem with a continuous one and thereby capitalize on
% reparameterization gradients~\citep{Kingma2014, rezende2014stochastic}
% to optimize a variational lower bound on the marginal likelihood.
% Critically, the Gumbel-softmax method has a temperature parameter that
% tunes the degree to which the continuous density concentrates around
% the vertices, and recovers truly discrete inference in the
% zero-temperature limit.

% % Discrete/Simplex <-> Permutation/Birkhoff analogy 
% Just as one-hot vectors (discrete random variables) are the vertices
% of the simplex, permutation matrices are the vertices of the Birkhoff
% polytope, i.e. the set of doubly stochastic matrices.  Thus, we seek
% temperature-controlled relaxations of atomic densities on permutation
% matrices to continuous densities on the interior of the Birkhoff
% polytope.  Unfortunately, the dual constraints of row- and
% column-normalization required of doubly stochastic matrices present
% difficulties that are not faced in the categorical setting. However,
% we derive a variety of alternative continuous relaxations for the
% simplex and show that: (i) these relaxations achieve comparable
% performance to the Gumbel-softmax on tractable discrete inference
% tasks; and (ii) they naturally extend to relaxations of permutation
% inference problems.

Recently, there have been a number of proposals for extending the
reparameterization trick to high-dimensional discrete inference problems
% \footnote{Discrete inference is only problematic in the high
%   dimensional case, since in low dimensional problems we can enumerate
%   the possible values of~$x$ and compute the normalizing
%   constant~$p(y) = \sum_x p(y, x)$.}
via continuous relaxation~\citep{maddison2016concrete,
  jang2016categorical, kusner2016gans}.  The key here is a ``temperature''
knob that controls the degree of relaxation.  As we discuss below, our
approach can be seen as an extension of these ideas to discrete
inference problems with more complex structure, like permutation
matrices.

% These approaches are based on the following
% observation: one-hot vectors~$x \in \{0,1\}^N$ can alternatively be
% viewed as vertices of the simplex~$\Delta_N$; likewise, discrete
% probability mass functions~$q(x; \theta)$ can be seen as atomic
% densities on the vertices of the simplex.  This motivates a natural
% relaxation: let~$x$ assume any value in the simplex, not just the
% vertices, and let~$q(x; \theta)$ be a density on the interior of the
% simplex.  One way to define such a density is via the following
% reparameterization,
% \begin{align}
%   \xi &\sim r(\xi), \\
%   g(\theta, \xi) &= \left[ \frac{\theta_1 + \xi_1}{\sum_{n=1}^N \theta_n + \xi_n},
%       \ldots,
%       \frac{\theta_N + \xi_N}{\sum_{n=1}^N \theta_n + \xi_n}
%       \right]
%     \triangleq \mathrm{softmax}(\theta + \xi),
% \end{align}
% where~${\xi, \theta \in \reals^N}$.  

% In the aforementioned papers, the noise is assumed to be a vector of
% independent Gumbel random variables,
% i.e.~${p(\xi) = \prod_{n=1}^N \mathrm{Gumbel}(\xi_n \given 0, 1)}$.
% This choice leads to a nicely interpretable model: adding Gumbel noise
% and taking the \emph{argmax} of~$\theta + \xi$ yields an exact sample from~$\pi = \mathrm{softmax}(\theta)$, thus
% the \emph{softmax} of~$\theta + \xi$ is a natural relaxation. Ultimately,
% however, this is just a continuous relaxation of an atomic density to
% a continuous density.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=5.in]{../figures/figure1.pdf} 
  \caption{Reparameterizations of discrete polytopes.  (a,b) The
    Gumbel-softmax, or ``Concrete'' transformation maps points
    ${\psi \in \reals^N}$ to points~${x \in \Delta_{N}}$ by adding
    noise and applying the softmax.  Here we show a slice for~$N=3$
    with~$\psi_3=0$. Colored points are aids to visualize the
    transformation.  (c,d) Stick-breaking offers and alternative
    transformation, here from points~$\psi \in [0,1]^{N-1}$ to~$\Delta_N$.
    The ordering of the stick-breaking induces an asymmetry in the
    transformation.  (e,f) We extend this stick-breaking transformation
    to reparameterize the Birkhoff polytope, i.e. the set of doubly
    stochastic matrices. Here,~$\mcB_3$ is reparameterized in terms
    of matrices~$\Psi \in [0,1]^{2 \times 2}$, of which three coordinates
    are shown in (e).  These points are mapped to doubly stochastic
    matrices, which we have projected onto~$\reals^2$ in panel~(f).}
\label{fig:transforms}
\end{figure*}

\subsection{Related Work}
A number of previous works have considered approximate methods of
posterior inference over the space of permutations.
% When a point
% estimate will suffice, convex relations are commonly
% employed~\citep{fogel2013convex, lim2014beyond}. Given noisy
% measurements of a sum of a small number of permutation matrices, we
% can recover the underlying coefficients via a convex optimization
% penalized by the norm induced by the Birkhoff
% polytope~\citep{chandrasekaran2012convex}.  For some ranking problems,
% we can rewrite the objective function in terms of the expected
% assignment probabilities under a distribution over permutation
% matrices, which in turn are points in the Birkhoff
% polytope. \citet{adams2011ranking} leveraged this property to develop
% stochastic gradient descent algorithms that minimize these objective
% functions, using Sinkhorn propagation~\citep{knight2008sinkhorn} as a
% differentiable map from the positive orthant to the Birkhoff polytope.
% We will use the same approach in one of our proposed methods.
When a point estimate will not suffice, sampling methods like Markov
chain Monte Carlo (MCMC) algorithms may yield a reasonable approximate
posterior for simple problems~\citep{diaconis1988group}.
\citet{harrison2013importance} developed an importance sampling
algorithm that fills in count matrices one row at a time, showing
promising results for matrices with~$O(100)$ rows and columns.  It may
also be possible to turn the Hungarian algorithm into an efficient
sampling algorithms using Perturb-and-MAP \citep{li2013efficient}.
Another line of work considers inference in the spectral domain,
approximating distributions over permutations with the low frequency
Fourier components~\citep{kondor2007multi, huang2009fourier}.  Perhaps
most relevant to this work, \citet{plis2011directional} propose a
continuous relaxation from permutation matrices to points on a
hypersphere, and then use the von Mises-Fisher (vMF) distribution to
model distributions on the sphere's surface. While the vMF
distribution does have a concentration parameter, as the concentration
goes to infinity, the distribution converges to a point on the sphere.
By contrast, we will derive temperature-controlled densities over
points inside or near the Birkhoff polytope such that as the
temperature goes to zero, the distribution converges to an atomic
density on permutation matrices.


 
\section{Variational permutation inference via reparameterization}
\label{sec:permutation}

The key to stochastic variational inference with the reparameterization
trick is an invertible and differentiable mapping~$x=g(\xi; \theta)$.
With this mapping, a simple noise density~$r(\xi)$ is transformed
into a variational posterior density~$q(x; \theta)$ that can be
sampled and evaluated pointwise---the necessary ingredients for
computing the stochastic gradients of the ELBO~\eqref{eq:elbo}.
For discrete variational inference via continuous relaxation,
we further require a temperature control.  Here we develop two
mappings for permutation inference.

\subsection{Stick-breaking transformations of the Birkhoff polytope}
Let~$\Psi$ be an arbitrary matrix in~${[0,1]^{(N-1) \times (N-1)}}$; we will
transform it into a doubly stochastic
matrix,~$X \in [0,1]^{N \times N}$ by filling in entry by entry, starting
in the top left and raster scanning left to right then top to
bottom. Denote the~$(m,n)$-th entries of~$\Psi$ and~$X$ by~$\psi_{mn}$
and~${x}_{mn}$, respectively.

Each row and column has an associated unit-length ``stick'' that we
allot to its entries.  The first entry in the matrix is given by,
$x_{11} = \psi_{11}$.  As we work left to right in the first row, the
remaining stick length decreases as we add new entries. This reflects
the row normalization constraints.  Formally, the stick-breaking
transformation for the first row is given by,
\begin{align*}
  x_{1n} &= \psi_{1n} \left(1 - \sum_{k=1}^{n-1} x_{1k} \right)  & &  \text{for } n=2, \ldots, N-1\\
  x_{1N} &= 1 - \sum_{n=1}^{N-1} x_{1n}.
\end{align*}
However, the remaining rows must now conform to both row- and
column-constraints. That is,
\begin{align*}
x_{mn} &\leq 1- \sum_{k=1}^{n-1} x_{mk} & & \text{(row sum)} \\
x_{mn} &\leq 1- \sum_{k=1}^{m-1} x_{kn} & & \text{(column sum)}.
\end{align*}
Moreover, there is also a lower bound on~$x_{mn}$. This entry must
claim enough of the stick such that what is leftover fits within
the confines imposed by subsequent column sums. That is, each column
sum places an upper bound on the amount that may be attributed to any
subsequent entry. If the remaining stick exceeds the sum of these
upper bounds, the matrix will not be doubly stochastic.  Thus,
\begin{align*}
\underbrace{1 - \sum_{k=1}^n x_{mk}}_{\text{remaining stick}}
  &\leq \underbrace{\sum_{j=n+1}^N (1- \sum_{k=1}^{m-1} x_{kj})}_{
    \text{remaining upper bounds}}.
\end{align*}
Rearranging terms, we have,
\begin{align*}
  x_{mn} &\geq
  % 1- \sum_{k=1}^{n-1} x_{mk} - \sum_{j=n+1}^N (1- \sum_{k=1}^{m-1} x_{kj}) \\
1 - N + n - \sum_{k=1}^{n-1} x_{mk}  +  \sum_{k=1}^{m-1} \sum_{j=n+1}^N x_{kj}.
\end{align*}
Of course, this bound is only relevant if the right hand side is greater than zero.
Taken together, we have~$\ell_{mn} \leq x_{mn} \leq u_{mn}$, where,
\begin{align*}
\ell_{mn} &\triangleq \max \left \{0, \, 1 - N + n - \sum_{k=1}^{n-1} x_{mk}  +  \sum_{k=1}^{m-1} \sum_{j=n+1}^N x_{kj} \right \}
\\
u_{mn} &\triangleq 
\min \left \{1- \sum_{k=1}^{n-1} x_{mk}, \,
1- \sum_{k=1}^{m-1} x_{kn} \right\}.
\end{align*}
Accordingly, we define,~${x_{mn} = \ell_{mn} + \psi_{mn} (u_{mn} - \ell_{mn})}$.
The inverse transformation from~$X$ to $\Psi$ is analogous.
We start by computing~$\psi_{11}$ and then progressively compute
upper and lower bounds and set~${\psi_{mn} = (x_{mn} - \ell_{mn})/(u_{mn} - \ell_{mn})}$.

To complete the reparameterization, we define a parametric,
temperature-controlled density for~$\Psi$.
Let~${\Xi \in \reals^{(N-1) \times (N-1)}}$ be a matrix of standard
Gaussian random variables.  We
define,
\begin{align*}
  \psi_{mn} &= \sigma\left( \frac{\mu_{mn} + \eta_{mn} \Xi_{mn}}{\tau} \right),
\end{align*}
where~${\theta = \{\mu_{mn}, \eta^2_{mn}\}_{m,n=1}^N}$ are the mean
and variance parameters of the
mapping,~${\sigma(u) = (1+e^{-u})^{-1}}$ is the logistic function,
and~$\tau$ is a temperature parameter. As~$\tau \to 0$, the values
of~$\psi_{mn}$ are pushed to either zero or one, depending on whether
the input to the logistic function is negative or positive,
respectively.  As a result, the doubly-stochastic output matrix~$X$ is
pushed toward the extreme points of the Birkhoff polytope, the
permutation matrices.


\subsection{Rounding toward permutation matrices}
\label{sub:rounding}

While relaxing permutations to the Birkhoff polytope is intuitively
appealing, it is not strictly required.  For example, consider the
following procedure for sampling a point \emph{near} the Birkhoff
polytope:
\begin{enumerate}[label=(\roman*)]
\item Input a point~${M \in \reals_+^{N \times N}}$;
\item Project~$M$ onto the Birkhoff polytope (approximately) using the Sinkhorn-Knopp algorithm;
\item Sample a Gaussian random variable~$\Psi$ with mean~$\mathrm{proj}(M)$ and variance~$\Sigma$;
\item Find the permutation matrix~${P^*(\Psi)}$ nearest to~$\Psi$ using the Hungarian algorithm;
  and
\item Return~${X = \tau \Psi + (1-\tau) P^*(\Psi)}$.
\end{enumerate}
This procedure implicitly defines a distribution over matrices~$X$.
Steps (i) and (ii) involve differentiable transformations of
parameter~$M$ to set the mean close to the Birkhoff polytope; the only
challenge in computing the density~$p(X; M, \Sigma)$ stems from step
(iv), since the rounding operation is not differentiable.  However,
this operation is piecewise constant with discontinuities only at
points that are equidistant from two or more permutation matrices---a
set of measure zero.  In practice, we find that we can safely ignore
these discontinuities and treat~$P^*(\Psi)$ as constant
with respect to~$\Psi$.  Furthermore, note that~${P^*(\Psi) \equiv P^*(X)}$
so that the inverse transformation is~${\Psi = \tau^{-1}X - \tau^{-1}(1-\tau) P^*(X)}$.  Taken together,~$X$ is a linear function of a
Gaussian random variable and its density is,
\begin{align*}
  p(X; M, \Sigma) = \frac{1}{\tau} \distNormal \left( \frac{1}{\tau}X -\frac{1-\tau}{\tau} P^*(X); \, \mathrm{proj}(M), \Sigma \right).
\end{align*}
In the zero-temperature limit we recover a discrete distribution on
permutation matrices, and for~$\tau \in (0,1]$, the distribution is
continuous on~$\reals^{N \times N}$, with density concentrating near
the vertices.


\begin{figure*}[ht] 
   \centering
   \includegraphics[width=1.0\textwidth]{../figures/figure8.pdf}
   \caption{Matching experiment results. (a)Examples of center locations (circles) and noisy samples (squares), at different noise variances. (b) For illustration, histograms of the true and inferred posterior distribution of identities along the corresponding Bhattacharya distance (BD), for selected cases. Histogram indexes are sorted from the highest to lowest actual posterior probability. Only the 20 most likely configurations are shown, and the 21st bar collapses the mass of all remaining configurations. (c) Population results (histograms) across 200 experiment repetitions of each parameter configuration. .}
   \label{fig:matching}
\end{figure*}

\subsection{Comparing these approaches}

\todo[inline]{work in progress}

\begin{itemize}
\item Stick-breaking relaxes to~$\mcB_N$ whereas rounding is to reals; Birkhoff is intuitively nice.
\item Stick-breaking is~$O(N^2)$ whereas rounding requires~$O(N^3)$ Hungarian call.
\item Stick-breaking admits exact density on Birkhoff whereas rounding has weird measure-zero concerns.
\item Rounding easily handles constraints, hard to do this with stick breaking.
\item Rounding is more ``symmetric'' whereas stick-breaking has an implicit dependence on ordering.  This can have some pathological effects on the resulting distribution.
\item Neither admits simple pmf on permutations (contrast with Gumbel-softax).
\end{itemize}

\subsection{Implications for discrete variational inference}
\label{sec:alternative}

\todo[inline]{Discuss the relation to Gumbel-softmax and the analogy between relaxing one hot vectors to simplex and relaxing permutations to Birkhoff.}

% First, let us consider an alternative reparameterization of the simplex
% via a stick breaking construction. We break this into two steps. First,
% we transform the noise and parameters to a point in the~${N-1}$ dimensional
% unit hypercube,
% \begin{align}
%   \xi &\sim r(\xi), & 
%   \psi & = f(\theta, \xi),
% \end{align}
% where~${\psi \in [0,1]^{N-1}}$. Then we transform the hypercube to~$\Delta_N$
%   via a stick-breaking transformation,
% \begin{align}
%   x_n = g_n(\psi)
%   &= \begin{cases}
%     \psi_1 & n=1, \\
%     \psi_n \left(1- \sum_{m=1}^{n-1} x_m \right) & 1 < n < N, \\
%     1- \sum_{n=1}^{N-1} x_n & n=N.
%     \end{cases}
% \end{align}
% The intermediate values~$\psi_n$ can seen as the fraction of the
% remaining ``stick'' of probability mass assigned to~${\pi}_n$.  In
% addition to its use in Bayesian nonparametrics, this type of
% transformation has been used in efficient MCMC algorithms for
% multinomial and categorical inference \citep{linderman2015dependent}.

% We focus on standard Gaussian noise~${r(\xi) = \mathcal{N}l(0,I)}$
% and we take~$f$ to be a logistic
% transformation~${\psi_n = \sigma((\mu_n + \eta_n \xi_n) / \tau)}$,
% where ${\sigma(u) = (1+e^{-u})^{-1}}$ is the logistic function
% and~$\tau$ is a \emph{temperature} parameter.  This
% \emph{logistic-normal stick breaking} transformation is parameterized
% by~${\theta = \{\mu_n, \eta_n\}_{n=1}^{N-1}}$, and it enjoys following
% properties: i)~the density of~$x$ can be expressed in closed form as a
% function of~$\mu_n$ and~$\eta_n^2$; ii)~the temperature~$\tau$
% controls how concentrated $p(x)$ is at the vertices of the simplex;
% iii)~with appropriate choices of parameters, in the limit
% ~$\tau \to 0$ we can recover any categorial distribution, i.e., the
% density becomes concentrated on atoms at the~$N$ vertices; and iv)~as
% ~$\tau \to \infty$, the density concentrates on a point in the
% interior of the simplex determined by the parameters. For all
% intermediate temperatures, the density is continuous on the simplex.

% Note that the logistic-normal stick breaking transformation one of
% many available. For example, we could take~$r$ and $f$ to be a
% reparameterization of the Kumaraswamy of beta distributions on the
% unit interval. The former is easily reparameterizable and the
% latter---which leads to the generalized Dirichlet distribution on the
% simplex---can be reparameterized following~\citet{naesseth2017reparameterization}. We include proofs of points (i-iv) and details of the Kumaraswamy and beta stick breaking constructions in the appendix.

% \parhead{Rounding}
% Both the Gumbel-softmax and stick-breaking relaxations consider
% distributions on the simplex, and while this
% offers an intuitive interpretation, it is not strictly required.  For
% example, first consider a distribution on~$\psi \in \reals^N$. These
% points are the rounded to the nearest vertex of the simplex via the
% operator,
% \begin{align}
%   \mathrm{round}(\psi) &= \argmin_{e_n} \| \psi - e_n \|.
% \end{align}
% % This operator partitions~$\reals^N$ into ``Voronoi'' cells
% % centered on the~$N$ vertices,
% % \begin{align}
% %   V_n &=
% %         \left\{\psi \in \reals^N: \, 
% %         \| \psi - e_n \| \leq \| \psi - e_m \| \;
% %         \forall m \in 1, \ldots, N \right\}.
% % \end{align}
% Unfortunately this rounding operator is non-invertible and
% non-differentiable.  Thus, we instead consider a map that pulls a
% point towards its rounded value, by taking a convex combination
% between both. Specifically, we consider the following reparameterization:
% \begin{align}
%   \xi &\sim p(\xi), \\
%   \psi &= f(\theta, \xi), \\
%   x &=  \tau \psi + (1-\tau) \cdot \mathrm{round}(\psi) .
% \end{align}
% In the zero-temperature limit we recover a discrete distribution on
% the vertices. For~$\tau > 0$, the distribution is continuous
% on~$\reals^N$. If the distribution of~$\psi$ is concentrated
% near the simplex---e.g. if~$\theta$ is a point on the simplex
% and~$\xi$ is small, additive Gaussian noise---the rounded points
% will lie close to the simplex as well. Moreover, this technique
% is easily generalized to more complex discrete polytopes. 
% % Moreover, this approach can be generalized to arbitrary discrete we
% % can represent any arbitrary categorical distribution over one-hot
% % vectors. This is shown in the appendix.

\section{Synthetic Experiments}
\label{sec:results}

We are interested in two principal questions: (i) how sensitive
are categorical relaxations to the choice of Gumbel-softmax,
stick-breaking, or categorical reparameterization? (ii) how
well can the stick-breaking and rounding reparameterizations
of the Birkhoff polytope approximate the true posterior distribution
over permutations in tractable, low-dimensional cases? and (iii)
when, if ever, do our proposed continuous relaxations offer
advantages over alternative approximate Bayesian permutation
inference algorithms?  We will address these questions in turn,
but first we discuss some practical details of our experimental
protocol.

\subsection{Experimental protocol}
\label{sub:protocol}
\parhead{Continuous prior distributions. } Continuous relaxations requires
re-thinking of the objective. As in \cite{maddison2016concrete}, we
maximize a relaxed ELBO, for which we need to specify a new continuous
prior $p(x)$ over the latent variables.
% Not sure I agree with all of this...
% This prior should be peaked around
% the discrete points for which inference is required, so we can
% conceive the original discrete ELBO through a limiting process. Good,
% peaked priors are necessary as the likelihood $p(y \given x)$ could be
% large for points that have nothing to do with the original problem,
% leading to nonsensical solutions. There is a trade-off, though: priors
% that are too peaked will lead to multiple local maxima of the ELBO,
% preventing optimizers from achieving the right solution. Then, for
% optimal performance the prior has to be treated as a
% hyperparameter.
For the categorical experiments, we use a mixture of Gaussians around
each vertex,~${p(x) = \tfrac{1}{N} \sum_{n=1}^N \mathcal{N}(x \given e_k, \eta^2)}$. For permutations, we use a mixture of Gaussians for each
dimension,
\begin{align}
\label{eq:permprior}
  p(X) &= \prod_{m=1}^N \prod_{n=1}^N
  \frac{1}{2} \left(\mathcal{N}(x_{mn} \given 0, \eta^2) + \distNormal(x_{mn} \given 1, \eta^2 \right).
  \end{align}
Although this prior puts significant mass invalid points
(e.g.~$\bone$), it penalizes $X$ that far from~$\mcB_N$.

\parhead{Estimating the ELBO. } Notice in all the relaxations
discussed here,~${x = g(\psi)}$ and~${\psi = f(\theta,
  \xi)}$. Moreover, both~$g$ and~$f$ are differentiable and invertible
functions. Therefore, by the change of variable theorem and the law of
the unconscious statistician:
\begin{align}
  \bbE_{r(\xi)} \left[- \log q(g(f(\theta, \xi)); \theta) \right]
  &= \bbH(\psi; \theta)+
    \bbE_{r(\xi)}\left[\log \left|\frac{\partial}{\partial \psi} g(f(\theta, \xi)) \right| \right],
  \end{align}
where~$\bbH$ is the entropy and the term inside of the expectation
is the (log Jacobian of $g$ evaluated at $\psi =
f(\theta,\xi)$. Then, if this Jacobian and the entropy of $\psi$ are
available we can consider an unbiased, Monte Carlo estimator for the ELBO.
% \begin{align}
%   \hat{\mcL}(\theta) = Entropy(\psi) +  \frac{1}{L}\sum_{l=1}^L \left[ \log p(y,  g(\theta, \xi_l) ) +  \log |DF(g(\theta, \xi_l)|\right].
% \end{align}
For example, in the rounding transformation, $g$ is piecewise linear
\footnote{The set of discontinuities has Lebesgue measure zero so we
  can still apply the change of variables theorem.} and
$\log | \tfrac{\partial}{\partial \psi} g(f(\theta, \xi)) |= N\log
\tau$. Also, if $\psi$ is Gaussian its entropy is given by
$N\log(\eta^2 2\pi e )/2$.


\subsection{Variational Autoencoders (VAE) with categorical latent variables}
We first demonstrate that our proposed relaxations are sensible for
categorical random variables. We considered the density estimation
task on MNIST digits, as in \cite{maddison2016concrete,
  jang2016categorical}, where observed digits are reconstructed from a
latent discrete code. We used the continuous ELBO for training, and
evaluated performance based on the marginal likelihood, estimated
through the multi-sample variational objective of the discretized
model (via rounding the samples $\pi$) with $m=1000$. We trained our
models using ADAM in Tensorflow and compared against the method of
\cite{jang2016categorical}, finding similar results (Table 1). Our
best results were obtained with rounding. Our results suggest our
methods provide a viable alternative to the Gumbel-Softmax. Fig
~\ref{fig:VAE} shows a random selection of reconstructed images using
the different approaches.  By eye, the reconstructed images
and the latent codes seem very comparable. 



\begin{table}[t]
  \caption{Summary of results in VAE}
  \label{tab:vae}
  \centering
  \begin{tabular}{ll}
    \textbf{Method} & $- \log p(x)$ \\
    \hline
    Gumbel-Softmax    & 106.7 \\
    Concrete  &  111.5\\
    Rounding &  121.1 \\
    Stick-breaking & 119. 8\\
    \bottomrule
  \end{tabular}
\end{table}


% \begin{table*}[t]
%   \caption{Battacharya distances in the synthetic matching experiment}
%   \label{sample-table}
%   \centering
%   \begin{tabular}{llllllll}
%    & \multicolumn{1}{c}{Rounding} & \multicolumn{1}{c}{Stickbreaking} & \multicolumn{5}{c}{Mallows}\\
%     \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-8}
%     &    & &   $\theta=0.1$ &  $\theta=1$ & $\theta=2$ & $\theta=5$ & $\theta=10$ \\
%     \midrule
%     $\sigma=0.1$     & .06 & .09  &.93 &.51& .23  & .08 &.08\\
%     $\sigma=0.25$     & .21 & .23 & .92 &.53 & .33&  .27 &.27\\
%      $\sigma=0.5$     & .32 & .41 & .89 &.61 & .53&  .54& .54\\
%      $\sigma=0.75$     & .38   & .55 & .85 &.71 & .69&  .72 &.72\\
   
%     \bottomrule
%   \end{tabular}
% \end{table*}

 \subsection{Synthetic matching experiments}
 To assess the quality of our approximations for distributions over
 permutations, we considered a toy matching problem in which we are given the locations of~$N$ cluster centers and a corresponding set of~$N$
 observations, one for each cluster, corrupted by Gaussian noise.
 Moreover, the observations are permuted so there is no correspondence
 between the order of observations and the order of the cluster centers.
 The goal is to recover the posterior distribution over permutations.
 For~$N=6$, we can explicitly enumerate the~$N!=720$ permutations and
 compute the posterior exactly. 

 \begin{table}[h]
  \caption{Battacharya distances in the synthetic matching experiment for various methods and observation variances.}
  \label{sample-table}
  \centering
  \begin{tabular}{lllll}
    & \multicolumn{4}{c}{Variance $\sigma^2$} \\
    \cmidrule(lr){3-4} 
    \textbf{Method} & $.1^2$ & $.25^2$ & $.5^2$ & $.75^2$ \\
    \hline
    Stick-breaking & .09 & .23 & .41 & .55 \\
    Rounding & \textbf{.06} & \textbf{.21}  & \textbf{.32}  & \textbf{.38} \\
    Mallows $(\theta=0.1)$ & .93 & .92 & .89  & .85 \\
    Mallows $(\theta=0.5)$ & .51 & .53  & .61 & .71 \\
    Mallows $(\theta=2)$ & .23 & .33 & .53  & .69 \\
    Mallows $(\theta=5)$ & .08 & .27 & .54 & .72 \\
    Mallows $(\theta=10)$ & .08 & .27 & .54  & .72 \\
    \bottomrule
  \end{tabular}
\end{table}

 We measured the discrepancy using the Battacharya distance (BD)
 between true posterior and an empirical estimate of the inferred
 posterior constructed by sampling from $q(X; \theta)$ and 'rounding'
 to the nearest permutation using the Hungarian algorithm. We found
 that our methods provide reasonable approximations to the true
 posterior, allowing us to represent more complex distributions over
 permutations than, e.g., simple Mallows distribution around the MAP
 estimate. Fig ~\ref{fig:synthetic} shows
 examples of true posteriors (ranked) and their approximations, and
 quantifies the discrepancies by the distribution of the BD.


\section{Inferring neuron identities in \textit{C. Elegans}}

\label{sec:synth_celegans}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=5.in]{../figures/figure6.pdf} 
  \caption{Problem setup. (a) Hermaphrodite C.elegans reference
    connectome (from \cite{varshney2011structural,wormatlas})
    consisting of 278 somatic neurons, merging two distinct types of
    synapses: chemical and electrical (gap junctions). (b) Example of
    matrix $W$ consistent with the connectome information (only 14
    neurons for visibility), (c) Distribution of neuron position in
    the body, zero means head and one means tail. From
    \cite{white1986structure,wormatlas} (d). Examples of the dynamical
    system sampled from matrix $W$}
  \label{fig:connectome}
\end{figure*}

We conclude by showing an application of our method to the problem of inference of identity in a dynamical system. This example is motivated by the study of the neural dynamics in the \textit{Caenorhabditis elegans} (C.elegans)  \cite{Kato2015}, a nematode (worm) of particular interest for neuroscience, as its neural network is stereotypical from animal to animal. Recent efforts have focused on establishing a self-consistent, accurate and complete neural wiring diagram from anatomical data ~\citep{varshney2011structural}. This diagram --- the connectome --- is utimately represented as a graph whose nodes are neurons (there are 278 somatic neurons for the hermaphrodyte C.elegans) and whose edges are synapses. Fig ~\ref{fig:connectome}a shows the corresponding adjacency matrix, that we refer to as $\mathcal{C}$.

The C.elegans, then, is particularly suited from investigating how patterns of neural activity gives rise to behaviour, a question that has been recently rigorously addressed \cite{Kato2015}. However, there, intensive manual data curation was needed in order to match neural recordings from calcium imaging techniques to actual neurons. This manual analysis was based on the study of joint patterns of neural activity, and the comparison of observed linear position of recorded neurons to a reference worm. In some cases, identity could not be exactly resolved, and only putative candidates were inferred. Unfortunately, besides this lack of certainty, this manual method does not scale if one requires to do inference in real time, or perhaps in experimental protocols that includes neural stimulation (e.g., using optogenetics \cite{Grosenick2015}). 

This difficulty offers fertile ground for the development of new methods. Recently, promising approaches \cite{Aoki2017} have illustrated the plausibility of using the Brainbow technology \cite{Livet2007} for such purposes, by genetically engineering worms to express fluorescent proteins. Then, neural identification is greatly facilitated in combination with standard microscopy techniques.

We prototype an alternative solution that bypasses the need for such sophisticated genetic engineering. Our method, in essence, embodies the criteria of manual data curation into an algorithm: the assumption is that neural identity could be resolved if enough information were available from the connectome, some covariates (e.g. position) and neural dynamics. Moreover, given the neural system changes little from worm to worm, one should be able to combine recording from many individuals to resolves identity in hard cases, based on a hierarchical bayesian model.

\subsection{Probabilistic Model}
We consider $n=1,\ldots, M$ linear (for simplicity) dynamical systems recorded during $t=1,\ldots, T$ time-steps $Y^m_t=P_mWP_m^\top Y_{t-1}+\varepsilon_t$ (Fig ~\ref{fig:connectome}d). Each of the $Y^m$ is a $N=278$ dimensional vector representing the recorded activity of the entire nervous system. These recordings are a permutation (represented by $P_n$) of the dynamics in a canonical order.  Entries of $W$\footnote{Alternatively, one could have chosen a hierarchical model of $W_m\sim p(W)$, a direction that we avoided here for the sake of simplicity.} are chosen consistently with the connectome: i.e., $W_{i,j}=0$ if $\mathcal{C}_{i,j}=0$. The remaining non-zero entries are then independently sampled from a normal distribution, and scaled by a factor of the spectral radius to ensure stability (see Fig ~\ref{fig:connectome}b for an example of $W$, and see appendix for further details).

We perform variational inference on this model for the joint estimation of the posterior probability of $P_m$ and $W$ given  $Y_m$ \footnote{$\varepsilon$ is assumed known for simplicity, but could otherwise be included in the posterior, or be directly estimated from data}. For $W$ we use a gaussian prior $p(W)\sim \mathcal{N}(0, I)$. Also, for $P_m$ we consider (at training) a relaxation based on the rounding approximation, and choose the prior defined in equation ~\ref{eq:permprior}. 

\begin{figure*}[ht]
  \centering
  \includegraphics[width=5.in]{../figures/figure7.pdf} 
  \caption{Results on the C.elegans inference example. (a) An example of convergence of the algorithm, and the baselines. (b) Accuracy on identity inference as a function of number of worms, for two values of $\nu$ ($\nu=$ for circles and $\nu=$ for squares). (c) Same as in (b), but using sub-networks of different size and $M=5$ worms. (d) Two samples of permutation matrices (left) and their noisy, non-rounded version (right) during the execution of the algorithm. The average of many samples is also shown, and existence of grey spots indicate that the sampling procedure is indeed non-deterministic.}
\label{fig:elegantresults}
\end{figure*}


The true posterior $p(W,P_m|Y)\propto p(Y|W,P_m)\times p(W)\prod_{m=1}^M p(P_m$) is then approximated by a variational family $q$ of the form $q(W,P_m)\equiv q(W)\prod_m^M q(P_m)$, where $q(W)$ is also gaussian and $q(P_m)$ has the distribution described in ~\ref{sub:rounding}. 

Finally, we use neural position along the worm's body to constrain the number of possible neural identities for a given neuron: specifically, relative positions of each neuron have been documented as numbers between zero and one \cite{white1986structure,wormatlas} , under the abstraction that a worm can be represented as one-dimensional object (Fig ~\ref{fig:connectome}c). Then, given this stablished data, the estimated position of all (or some) neurons, and a tolerance $\nu$, we can conceive a binary \textit{confusion} matrix $D^m$ so that $D^m_{i,j}=1$ if (observed) neuron $i$ is close enough to (canonical) neuron $j$; i.e., if their distance is smaller than $\nu$. We then enforce that constrain during inference, by ensuring that $P_{m_{i,j}}=0$ if $D^m_{i,j}=0$. This can be easily done by multiplying by zero such entries in the parameter matrix $\widetilde{\Theta}$ described in ~\ref{sub:rounding}. Besides ease in inference,  this modeling choice greatly reduces the number of effective parameters of the model, promoting scalability. Also, we allow for a certain number of neural identities to be known beforehand, easily encoded in $D^m$ as well.

\subsection{Results}

We compared against three methods: i) naive variational inference, where we don't enforce the constraint that $P$ is a permutation but allow many neurons to be mapped to the same one, ii) MCMC, where one alternates between sampling from the conditionals of $W$ (gaussian) and $P_m$, from which one can sample by proposing local swipes, as described in \cite{Diaconis2009}, and iii) MAP estimator, which can be understood as a 'hard' version of ii); instead of iteratively sampling, we alternate between the MAP estimate of $W$ (a ridge regression-like expression) and the MAP of the $P_m$'s. For the $P_m$'s we notice the objective is a quadratic assignment problem (QAP) in $P_m$, that is, it can be expressed as $Trace(APBP^\top)$ for some matrices $A,B$. We used the QAP solver proposed in \cite{Vogelstein2015}. 

Results show that in our data our method outperforms each of the three baselines. This is illustrated in Fig ~\ref{fig:elegantresults}: Fig \ref{fig:elegantresults}a depicts convergence to a better solutions, for a certain parameter configuration. More conclusively, Fig \~ref{fig:elegantresults}b shows a clear dominance in our method when varying the number of neurons. Likewise, Fig \~ref{fig:elegantresults}c depicts a similar finding when varying the size of the network. Here, variational inference and MCMC perform equally well in a regime where there is enough certainty about neural identity (squares), but when location information is more imprecise variational inference does better. This suggests our method might be particularly useful to  profit from this kind of side information. 


\section{Discussion}
Our results provide evidence that permutation variational inference might provide a helpful tool for the inference of neural identity, as it allows to properly represent shared information across animals, and different degrees of certainty based on covariates. In order to apply it to real data it is necessary to consider more realistic models of neural dynamics, which are non-linear but might be well characterized, for example, by a set of atomic low-dimensional linear dynamical systems, each of one corresponding to a certain behavioral state  \cite{Kato2015}. The methodology developed in \cite{Linderman2016} seems particularly suitable to harness that increased level of complexity. \

\bibliography{refs}
\bibliographystyle{abbrvnat}

\appendix
\section{Supplemental result on MNIST}
\begin{figure*}[t]
  \centering
  \includegraphics[width=5.in]{../figures/figure4.pdf} 
  \caption{Examples of true and reconstructed digits from their corresponding random codes using with $N=20$ categorical variables with $K=10$ possible values.
  }
\label{fig:synthetic}
\end{figure*}


\section{Limit analysis}
\subsection{Stick-breaking}
Here we state and prove that for all the stick-breaking based distributions in the simplex we consider here; based on the Logistic-gaussian, Kumaraswamy, and Beta distributions, we can arrive to any point in the interior of the simple or any categorical distribution as limiting cases (in $\tau$). First, we need some lemmas.


\textbf{Lemma 1.}  The following statements are true:
\begin{enumerate} \item the degenerate case where  $z_k$ is deterministic leads to $\pi\sim \delta(\tilde{\pi})$  (i.e, single atom in the point $\tilde{\pi}$). Also, if $z_k$ can be any in $(0,1)$ then any deterministic $\pi$ in the interior of the simplex can be realized.
\item the degenerate case where  $z_k$ are Bernoulli with parameter $p_k(\theta) \in (0,1)$ leads to $\pi$ having an atomic distribution with atoms in the vertices of $\Delta^{k-1}$; i.e, $\pi$ is categorical. We have the following expression for the probabilities of the atoms $\pi_k=1$ (one hot vectors):
\begin{align}
\label{eq:onehotprob}
P(\pi_k =1)&= \prod_{i=1}^{k-1} (1-p_i(\theta)) p_k(\theta)  \;\; \text{for } k=2, \ldots, K-1, \quad P(\pi_K =1) = \prod_{i=1}^{K-1} (1-p_i(\theta)).
\end{align}

Moreover, if for each index $k$ any parameter of the Bernoulli variable $z_k$ can be realized through appropriate choice of $\theta$, then any categorical distribution can be realized.

\end{enumerate}
\textit{Proof}: (a) both claims are obvious and come from the invertibility of the function $\mathcal{SB} \circ h (\cdot)$. (b) the formulae for $P(\pi_k =1)$ comes from expressing the event $\pi_k=1$ equivalently as $\pi_k=1,\pi_i=0, i<k$ and then, conditioning backwards successively. The second statement comes from the following expression, which easily follows  from \eqref{eq:onehotprob}:
$$ p_k(\theta)=\frac{P(\pi_k =1)}{P(\pi_{k-1} =1)}\frac{p_{k-1}(\theta)}{1-p_{k-1}(\theta)},\quad k =1,\ldots, K-1.$$
The recursive nature of the above equation gives a recipe to iteratively determine the required $p_k(\theta)$, given  $P(\pi_k =1), P(\pi_{k-1} =1)$ and the already computed $p_{k-1}(\theta)$.


Now we can state our results:

\textbf{Lemma 2.} If $z=\sigma(\psi),\psi\sim\mathcal{N}(\mu,\eta^2)$, then
\begin{enumerate} \item the  limit $\eta\rightarrow 0$ and $\mu$ fixed leads to the deterministic $z=\sigma(\mu)$. 
\item the limit $\mu\rightarrow \infty, \eta^2=\mu/K$ with K constant leads to $z\sim \text{Bernoulli}(\Phi(K))$, with $\Phi(\cdot)$ denoting the standard normal cdf.
\end{enumerate} In both cases the convergence is in distribution 

\textit{Proof}. The first convergence is obvious. To see the second, let's index $\mu_n$ and  study the cdf $F$ of $z_n$ on the interval (0,1) (it evaluates zero below zero and one above one).
\begin{align}F_{z_n}(x)&= P(\sigma(\psi_n)<x) \\
&=P(\psi_n< \sigma^{-1}(x))\\
&=P(\mu_n +\mu_n/K\xi <\sigma^{-1}(x)),\\\
&= P( \xi <\sigma^{-1}(x)K/\mu_n - K)\\
&= \Phi( \sigma^{-1}(x)K/\mu_n - K) 
\end{align}

Therefore, by continuity of $\Phi$ we obtain $F_{\Psi_n}(x)\rightarrow \Phi(-K)$ for all points $x\in(0,1)$. On the other hand, the cdf of a bernoulli random $F$ variable is given by  a step function that abruptly changes at zero, from zero to $1-p$, and at one, from $1-p$ to 1. As convergence occurs at all continuity points (the interval $(0,1)$), we conclude (recall, $1-p= \Phi(-K)\rightarrow \Phi(K)=p$). Notice that the above representation only allows  to converge to $p>0.5$, as $K$ has to be positive. This can be fixed by choosing sequence with negative $\mu$ instead.

\textbf{Lemma 3.} If $z=\mathcal{K}(a,b)$: \begin{enumerate}
\item in the limit $a,b \rightarrow $  we converge to deterministc $p$, provided that $p=bB\left(1+\frac{1}{a},b\right)$ along the limiting sequence.
\item In the limit $a,b\rightarrow 0$ we obtain convergence to a Bernoulli random variable with parameter $p$, provided the same condition involving $p,a,b$ holds. 
\end{enumerate}
In both cases convergence is in probability.
\textit{Proof}: A proof can be found in \cite{mitnik2013kumar}

\textbf{Lemma 4.} If $z=Beta(a,b)$: \begin{enumerate}
\item in the limit $a,b \rightarrow \infty $  we converge to deterministc $p$, provided that $p=bB\left(1+\frac{1}{a},b\right)$ along the limiting sequence.
\item In the limit $a,b\rightarrow 0$ we obtain convergence to a Bernoulli random variable with parameter $p$, provided the same condition involving $p,a,b$ holds. 
\end{enumerate}
In both cases convergence is in distribution.

\textbf{Proposition.} In all the discussed cases of re-parameterizations of the simplex via stick-breaking, arbitrary categorical distributions can be obtained in the low-temperature limit. Also, in the high-temperature convergence is to certain point(s) in the interior of the simplex.

\textit{Proof}: Consider each distribution separately
\begin{enumerate}
\item For the logistic-normal re-parameterization $z_k = \sigma\left( \frac{\mu_k+\eta_k\xi}{\tau}\right)$, in the low temperature case use Lemma 2 (b) by the always available representation  $K= \frac{\mu}{\eta^2}$and conclude by Lemma 1(b). In the high temperature case convergence is to the point $\pi = \mathcal{SB}(0.5,0.5,\ldots, 0.5)$.
\item For Kumaraswamy $z_k=\mathcal{K}(a_k,b_k)$ the argument is similar, but here the temperature can only be defined implicitly through sequences of parameters $(a_k,b_k)$ converging to either $\infty$ or 0 along a sequence with fixed $p_k=b_kB\left(1+\frac{1}{a_k},b_k\right)$. Then in the low temperature case we conclude by Lemma 3(b) and Lemma 1(b). In the hig-temperature case we converge to the point $SB(p_1,\ldots p_{k-1}$
\item For the Beta $z_k\sim Beta(\frac{a_k}{\tau},\frac{b_k}{\tau})$ low-temperature leads to convergence to $z_k$ Bernoulli with parameter $a_k/(a_k+b_k)$ and we conclude from Lemma 4(b) and Lemma 1(b). For high temperatures, convergence is to the point $\mathcal{SB}(a_k/(a_k+b_k),\ldots,a_{k-1}/(a_{k-1}+b_{k-1}))$.  \end{enumerate}


%\subsection{Rounding}
%Here we have two extremes: at $\tau =1$ we obtain a continuous distribution in the space (here, gaussian). If $\tau=0$ the resulting distribution has only atoms in the one-hot vectors $p_n$, in this proof assumed to be the one-hot vectors. We show that in this case it is possible to represent any arbitrary categorical distribution through a judicious choice of the parameters.


%\textbf{Proposition:} In the zero temperature case, i.e., $\pi  = R^\mathcal{P}(\psi)$ it is possible to represent any arbitrary distribution i.e, for any $\alpha$ in the $N-1$ simplex there exists gaussian parameters $(\mu, \eta)$ so that   $P(\pi = p_n)  = \alpha_n$. Points inside the simplex are realized directly, while distributions with some $\alpha_k=0$ are realized through a limiting process in the parameters.

%\textit{Proof:} First set $\eta_n=1$. By representing $\psi = \mu + \xi$ where $\xi\sim\distNormal(0, I)$ we see that
%$$\alpha_n = P(R^\mathcal{P}(\mu + \xi) = p_n ) = P(\mu + \xi \in V^\mathcal{P}_{n}) = P(\xi \in V^\mathcal{P}_{n} - \mu) =  \int_{V^\mathcal{P}_{n} - \mu} \frac{1}{(2\pi)^\frac{N}{2}}e^{-\frac{||x||^2}{2}} dx.$$
%Three conclusions are drawn from the above: first, we see that probabilities are ultimately gaussian integrals over a new partition, a translation of the Voronoi regions $V^\mathcal{P}_{n}$. Second,
%the map $(\mu_1,\ldots,  \mu_n)\xrightarrow{m} (\alpha_1,\ldots, \alpha_n)$ is continuous by virtue of the dominated convergence theorem \cite{browder2012mathematical}: indeed, if $\mu_i\rightarrow \mu$ then $(\alpha^i_1,\ldots, \alpha^i_n) \rightarrow (\alpha_1,\ldots, \alpha_n)$, as the $\alpha^i_n$ are integrals that can be expressed using indicator functions in the integrands (which are all bounded by the integrable gaussian density), and as pointwise convergence of the indicators holds because of the continuity of the translation operator $f_\mu(\cdot) = \cdot + \mu$. Third, for each $q\in(0,1)$ it is possible to choose $\mu$ so that $\alpha_n =q$ and $\alpha_m = (1-q)/(n-1)$. Indeed, by moving $\mu_n$ between $-\infty$ and $\infty$ while keeping the other $\mu_k$ fixed then $V^\mathcal{P}_{n} - \mu$ fluctuates between the empty set ($\alpha_n =0$) and the entire space ($\alpha_n=1$). Therefore, by the continuity of $m$ and the intermediate value theorem, every value in $\alpha_n\in (0,1)$ is realized, and by symmetry the other $\alpha_k$ occupy the remaining mass uniformly. 

%To conclude, we use the fact that the image of a convex set through a continuous function is also convex \cite{Rockafellar70}. We also showed that for each tolerance $\epsilon$ the image of $m$ contains these $\epsilon$-one-hot vectors: that is, the points with $(1-\epsilon)$ in one coordinate and $\epsilon/ (n-1)$ in the rest. Then, given a point in the interior of the simplex choose $\epsilon$ small enough so it is in the convex hull of the $\epsilon$-one vectors. Then, by the above theorem there must be a pre-image $\mu$ that realizes this point.

%For $\alpha$ with zero entries the above arguments has to be extended to permit a limit process where $\mu$ goes to either infinity or infinity. It is easy to see that by that extension it is possible to represent any $\alpha$ in the border of the simplex.


\section{Deriving  the approximation for the ELBO}
Here we show that $$\E_{p(\xi)} \left[- \log q(F(g(\theta, \xi)); \theta) \right] = Entropy(\psi; \theta)+E_{p(\xi)}\left[\log | DF(g(\theta, \xi))|\right].$$
Indeed, first, by the `Law of the Unconscious Statistician' we have:
 $$\E_{p(\xi)} \left[- \log q(F(g(\theta, \xi)); \theta) \right] = \E_{p(\psi;\theta)} \left[- \log q(F(\psi); \theta) \right]. $$
Now, by the change of variable theorem and derivative and determinant inversion rules, we obtain:\begin{align}
q(F(\psi); \theta) & = p(F^{-1}(\pi) ;\theta)  |DF ^{-1}(\pi) | \\
 & = p(\psi;\theta) | DF (\psi) | ^{-1}.
 \end{align}
 To conclude we use once more the Law of the Unconscious Statistician:
 \begin{align}
 \E_{p(\xi)} \left[- \log q(F(g(\theta, \xi)); \theta) \right]  &= \E_{p(\psi;\theta)}\left[ - \log p(\psi;\theta)\right] +   \E_{p(\psi;\theta)}\left[\log | DF(\psi)|\right] \\
 &= Entropy(\psi; \theta)+E_{p(\xi)}\left[\log | DF(g(\theta, \xi))|\right].\end{align}
 
 Notice $R^Z$ is a piecewise constant function, as maps each $V^\mathcal{P}_{m}$ to $p_m$

Notice that these bounds only depend on values of~${\Pi}$ that
have already been computed; i.e., those that are above or to the left of
the~$(i,j)$-th entry. Thus, the transformation from~$\Psi$ to~${\Pi}$
is feed-forward according to this ordering.  Consequently, the
Jacobian of the inverse transformation,~$\mathrm{d}\Psi / \mathrm{d} \Pi$,
is lower triangular, and its determinant is the product of its diagonal,
\begin{align}
\left| \frac{\mathrm{d} \Psi } {\mathrm{d} \Pi} \right|
&= \prod_{i=1}^{n-1} \prod_{j=1}^{n-1} \frac{\partial \psi_{ij} }{\partial {\pi}_{ij}} \\
&= \prod_{i=1}^{n-1} \prod_{j=1}^{n-1} \frac{\partial}{\partial {\pi}_{ij}}
\sigma^{-1} \left( \frac{{\pi}_{ij} - \ell_{ij}}{u_{ij} - \ell_{ij}} \right ) \\
&= \prod_{i=1}^{n-1} \prod_{j=1}^{n-1}
\left( \frac{1}{u_{ij} - \ell_{ij}} \right )
\left( \frac{u_{ij} - \ell_{ij}}{{\pi}_{ij} - \ell_{ij}} \right )
\left( \frac{u_{ij} - \ell_{ij}}{u_{ij} - {\pi}_{ij}} \right ) \\
&= \prod_{i=1}^{n-1} \prod_{j=1}^{n-1}
\frac{u_{ij} - \ell_{ij}}{({\pi}_{ij} - \ell_{ij}) (u_{ij} - {\pi}_{ij})}
\end{align}

With these two ingredients, we can write the density of~${\Pi}$,
\begin{align}
  \text{vec} (\Psi) &\sim \distNormal(\mu, \diag(\eta^2))
  \\
  {\Pi} &= f(\Psi) \\
  \implies
  p(\Pi \given \mu, \diag(\eta^2)) &= \left|\frac{\mathrm{d} \Psi }{\mathrm{d} {\Pi}} \right|
  \distNormal(f^{-1}({\Pi}) \given \mu, \diag(\eta^2))
\end{align}

Given the density and a differentiable mapping we can perform
variational inference with stochastic optimization of the ELBO.
We define a distribution over doubly stochastic matrices as a
reparameterization of a multivariate Gaussian distribution
over~$\Psi$. We can estimate gradients via the reparameterization
trick.

It is important to note that the transformation is only piecewise
continuous: the function is not differentiable at the points where
the bounds change; for example, when changing~$\Psi$ causes the
active upper bound to switch from the row to the column constraint
or vice versa.  I think we can argue that these discontinuities
will not have a severe effect on our stochastic gradient algorithm.

\end{document}
