{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.expanduser(os.path.join(\"~\", \"Projects\", \"birkhoff\")))\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/birkhoff/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/src/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import logsumexp\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "import timeit\n",
    "\n",
    "from birkhoff.primitives import gaussian_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "color_names = [\"red\",\n",
    "               \"windows blue\",\n",
    "               \"amber\",\n",
    "               \"faded green\",\n",
    "               \"dusty purple\",\n",
    "               \"orange\",\n",
    "               \"clay\",\n",
    "               \"pink\",\n",
    "               \"greyish\",\n",
    "               \"light cyan\",\n",
    "               \"steel blue\",\n",
    "               \"pastel purple\",\n",
    "               \"mint\",\n",
    "               \"salmon\"]\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "from autograd import grad\n",
    "from autograd.optimizers import adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "npr.seed(0)\n",
    "K = 100\n",
    "D = 2\n",
    "eta = 0.5\n",
    "sigma_min, sigma_max = 1e-8, 1.0\n",
    "\n",
    "# Optimization parameters\n",
    "num_adam_iters = 1\n",
    "num_mcmc_samples = 1\n",
    "\n",
    "# Sample a true permutation (in=col, out=row)\n",
    "# perm_true = npr.permutation(K)\n",
    "perm_true = np.arange(K)[::-1]\n",
    "#perm_true = np.arange(K)\n",
    "P_true = np.zeros((K, K))\n",
    "P_true[np.arange(K), perm_true] = 1\n",
    "\n",
    "# Sample data according to this permutation\n",
    "xs = npr.randn(K, D)*10\n",
    "xs_perm = P_true.T.dot(xs)\n",
    "ys = xs_perm + eta * npr.randn(K, D)\n",
    "\n",
    "\n",
    "M = np.ones((K,K))\n",
    "M2 = np.zeros((K,K))\n",
    "listchar = npr.choice(K, K,replace= False)\n",
    "#listchar =[]\n",
    "\n",
    "for m in listchar:\n",
    "    i = np.where(P_true[m,:] ==1)[0]\n",
    "    #M[m, [j for j in range(K) if j not in [i]]] = 1e-8\n",
    "    random = npr.choice(K,80, replace = False)\n",
    "    M[m, [j for j in random if j not in [i]]] = 1e-8\n",
    "    M2[m, [j for j in random if j not in [i]]] = 100000000000\n",
    "    #print (i, random) \n",
    "    #print \n",
    "    #M[[j for j in range(K) if j not in [i]],m]=1e-8\n",
    "#print len(np.where(M.flatten()==1)[0])\n",
    "#M = np.dot(P_true.T, np.dot(deepcopy(M),P_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC1CAYAAAAZU76pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10633d210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot to and from\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "lim = max(abs(ys).max(), abs(xs).max())\n",
    "for k in range(K):\n",
    "    plt.plot(xs[k, 0], xs[k, 1], 'o',\n",
    "             color=colors[k % len(colors)],  markersize=6,\n",
    "             markeredgecolor='k', markeredgewidth=1)\n",
    "    plt.plot(ys[perm_true[k], 0], ys[perm_true[k], 1], 's',\n",
    "             markersize=6, color=colors[k % len(colors)],\n",
    "             markeredgecolor='k', markeredgewidth=1)\n",
    "\n",
    "# Scale bar\n",
    "plt.plot([lim-2*eta,lim], [-lim,-lim], '-k', lw=3)\n",
    "\n",
    "plt.xlim([-1.25*lim, 1.25*lim])\n",
    "plt.ylim([-1.25*lim, 1.25*lim])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02431607246\n"
     ]
    }
   ],
   "source": [
    "# Compute the MAP assignment\n",
    "score = np.zeros((K, K))\n",
    "for i in range(K):\n",
    "    for j in range(K):\n",
    "#         score[i,j] = -0.5 * np.sum((ys[j] - xs[i])**2) / eta**2 \n",
    "        score[i,j] = np.sum(gaussian_logp(ys[j], xs[i], eta))\n",
    "row, col = linear_sum_assignment(-score)\n",
    "P_map = np.zeros((K, K))\n",
    "P_map[row, col] = 1\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "round_to_perm(npr.randn(300,300))\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build variational objective. The variational dist is \n",
    "# a diagonal Gaussian over the (K-1)**2 parameters\n",
    "\n",
    "\n",
    "# Build variational objective. The variational dist is \n",
    "# a diagonal Gaussian over the (K-1)**2 parameters\n",
    "limits = np.zeros((2,2))\n",
    "limits[0,0] = -5\n",
    "limits[0,1] = 5\n",
    "limits[1,0] = 0.00\n",
    "limits[1,1] = 0.01\n",
    "# Set up the log probability objective\n",
    "# Assume a uniform prior on P?\n",
    "# Right now this is just the likelihood...\n",
    "def perm_to_P(perm):\n",
    "        K=len(perm)\n",
    "        P = np.zeros((K,K))\n",
    "        P[range(K),perm] = 1 \n",
    "        return P\n",
    "\n",
    "def round_to_perm(P):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    K = P.shape[0]\n",
    "    \n",
    "    assert P.shape == (K, K)\n",
    "    row, col = linear_sum_assignment(-P)\n",
    "    P = np.zeros((K, K))\n",
    "    P[row, col] = 1.0\n",
    "    return P\n",
    "\n",
    "def unpack_params_sparse(params, K, M):\n",
    "    indexes = np.where(M.flatten() == 1)\n",
    "    logit_mu = []\n",
    "    logit_sigma = []\n",
    "    #logit_mu = np.zeros(K*K)\n",
    "    #logit_sigma = np.zeros(K*K)\n",
    "    #logit_mu[indexes[0]] = params[:n_params]\n",
    "    #logit_sigma[indexes[0]] = params[n_params:]\n",
    "    cont = 0\n",
    "    \n",
    "    for i in range(K*K):\n",
    "        if i in indexes[0]:\n",
    "            logit_mu.append(params[:n_params][cont])\n",
    "            logit_sigma.append(params[n_params:][cont])\n",
    "            cont+=1\n",
    "        else:\n",
    "            logit_mu.append(0)\n",
    "            logit_sigma.append(1)\n",
    "    #return unpack_params(params,K)\n",
    "    return np.reshape(np.array(logit_mu),(K,K)), np.reshape(np.array(logit_sigma),(K,K))\n",
    "    #return (logit_mu, logit_sigma)\n",
    "\n",
    "def logit(pi): return np.log(pi) - np.log(1-pi)\n",
    "def logistic(psi): return np.exp(psi)/(1+np.exp(psi))\n",
    "\n",
    "def rowwise_softmax(psi):\n",
    "    \n",
    "    maxes = np.amax(psi, axis=1)\n",
    "    maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "    e = np.exp(psi - maxes)\n",
    "    dist = (e.T / np.sum(e, axis=1)).T\n",
    "    return dist\n",
    "\n",
    "def columnwise_softmax(psi):\n",
    "    \n",
    "    maxes = np.amax(psi, axis=0)\n",
    "    maxes = maxes.reshape(1, maxes.shape[0])\n",
    "    e = np.exp(psi - maxes)\n",
    "    dist = (e/ np.sum(e, axis=0))\n",
    "    return dist\n",
    "\n",
    "\n",
    "def sample_to_pi(sample, temp):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    #s = sample * temp + (1 - temp) * round_to_perm(sample - M2) \n",
    "    #s = sample * temp + (1 - temp) * round_to_perm(sample )\n",
    "    s = sample\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print elapsed\n",
    "    return s\n",
    "    \n",
    "    # code you want to evaluate\n",
    "  \n",
    "    \n",
    "    #return sample\n",
    "\n",
    "def sample_pi_voronoi(params, noise,  temp, limits, M):\n",
    "   \n",
    "    K = noise.shape[1]\n",
    "    \n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params, K, M)\n",
    "    \n",
    "    mu = np.exp(logit_mu*M)\n",
    "    \n",
    "    for j in range(5):\n",
    "        \n",
    "        mu = rowwise_softmax(np.log(mu*M))\n",
    "        mu = columnwise_softmax(np.log(mu*M))\n",
    "    \n",
    "    sigma = limits[1, 0] + (limits[1, 1] - limits[1, 0]) * logistic(logit_sigma)\n",
    "    \n",
    "    sample = noise * sigma + mu\n",
    "    \n",
    "    \n",
    "    return (sample, np.array([sample_to_pi(sample[i,:,:], temp) for i in range(sample.shape[0])]))\n",
    "    \n",
    "def log_density_gaussian_voronoi(params, temp, limits, K):\n",
    "    \n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params,  K, M)\n",
    "    \n",
    "    sigma = limits[1, 0] + (limits[1, 1] - limits[1, 0]) * logistic(logit_sigma)\n",
    "    log_sigma =np.log(sigma)\n",
    "    entropy = 0.5 * log_sigma.size * (1.0 + np.log(2 * np.pi)) + np.sum(log_sigma)\n",
    "    \n",
    "    return entropy + K *(K) * np.log(temp)\n",
    "\n",
    "# Set up the log probability objective\n",
    "# Assume a uniform prior on P?\n",
    "# Right now this is just the likelihood...\n",
    "def log_prob(P, t):\n",
    "    return np.sum(gaussian_logp(ys, np.dot(P.T, xs), eta))\n",
    "    \n",
    "    \n",
    "def variational_objective(params, t, K, M):\n",
    "    \n",
    "    \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "    #noise = npr.randn(num_mcmc_samples, K, K)\n",
    "    noise = npr.randn(num_mcmc_samples, K, K)\n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params,  K, M)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # code you want to evaluate\n",
    "  \n",
    "    (samples, P_samples) = sample_pi_voronoi(params, noise, temperature(t), limits, M)\n",
    "    \n",
    "    \n",
    "    elbo = 0\n",
    "    \n",
    "    for P in P_samples:\n",
    "        elbo = elbo + log_prob(P,t) / num_mcmc_samples \n",
    "        \n",
    "    elbo = elbo + log_density_gaussian_voronoi(params, temperature(t), limits, K)\n",
    "        \n",
    "    return [-elbo, log_prob(P_samples[0],t),log_density_gaussian_voronoi(params, temperature(t), limits, K)]\n",
    " \n",
    "def callback(params, t, g, perline=10):\n",
    "    \n",
    "    num_mcmc_samples = 1\n",
    "    elbos.append(variational_objective(params, t, K, M))\n",
    "    params_all.append(params)\n",
    "    \n",
    "    \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "    def n_correct(P1,P2):\n",
    "        return P1.shape[0]- np.sum(np.abs(P1-P2))/2.0\n",
    "\n",
    "    \n",
    "    if (t % perline) == 0:\n",
    "        sys.stdout.write('. [Iter {0}/{1}] VLB: {2:.1f}\\n'.format(t, num_adam_iters, -elbos[-1][0]))\n",
    "        print elbos[-1]\n",
    "        noise = npr.randn(num_mcmc_samples, K, K)\n",
    "        (sample, P_samples) = sample_pi_voronoi(params, noise, temperature(t), limits, M)\n",
    "    \n",
    "        perm_inferred = linear_sum_assignment(-P_samples[0])\n",
    "        P_inf =perm_to_P(np.array(perm_inferred[1]))\n",
    "        print [log_prob(P_samples[0],5), log_prob(P_inf,5), log_prob(P_true,5), n_correct(P_true,P_inf)]\n",
    "       \n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational inference for matching...\n",
      "Initializing with MAP estimate\n",
      "2079\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ". [Iter 0/300] VLB: -171151.9\n",
      "[171151.93697825249, -40450.045636928786, -130701.8913413237]\n",
      "0.0\n",
      "[-40931.514133852717, -88167.102471165941, -135.77063693254146, 7.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".1.90734863281e-06\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ". [Iter 10/300] VLB: -154192.6\n",
      "[154192.5896639351, -23922.345051293662, -130270.24461264143]\n",
      "9.53674316406e-07\n",
      "[-23768.015760255192, -20515.847974177439, -135.77063693254146, 19.0]\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "0.0\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ". [Iter 20/300] VLB: -143924.8\n",
      "[143924.83398069133, -14067.56361331836, -129857.27036737297]\n",
      "0.0\n",
      "[-14174.388650977051, -13225.901331216937, -135.77063693254146, 29.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ". [Iter 30/300] VLB: -138233.7\n",
      "[138233.70017034782, -8762.7091656118191, -129470.99100473599]\n",
      "1.19209289551e-06\n",
      "[-8879.5342082595271, -7746.5227186117918, -135.77063693254146, 39.0]\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ". [Iter 40/300] VLB: -135084.8\n",
      "[135084.83215720835, -5969.0931490954445, -129115.7390081129]\n",
      "0.0\n",
      "[-5908.2724765260145, -2506.3344756329379, -135.77063693254146, 67.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".0.0\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ". [Iter 50/300] VLB: -132656.9\n",
      "[132656.88960671396, -3864.7237843117637, -128792.1658224022]\n",
      "1.19209289551e-06\n",
      "[-3924.9247633361147, -1868.8510682883646, -135.77063693254146, 76.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ". [Iter 60/300] VLB: -131188.8\n",
      "[131188.78089310348, -2688.6563099968189, -128500.12458310666]\n",
      "9.53674316406e-07\n",
      "[-2682.8296959030072, -1780.5877975044498, -135.77063693254146, 79.0]\n",
      "9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ". [Iter 70/300] VLB: -130230.8\n",
      "[130230.83235913259, -1992.5836228439903, -128238.2487362886]\n",
      "9.53674316406e-07\n",
      "[-1905.9365366838369, -1283.2731679554718, -135.77063693254146, 83.0]\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ". [Iter 80/300] VLB: -129499.8\n",
      "[129499.83945026009, -1494.9817516989951, -128004.85769856109]\n",
      "9.53674316406e-07\n",
      "[-1548.5964647167784, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ". [Iter 90/300] VLB: -128976.7\n",
      "[128976.66316343764, -1178.5369655601764, -127798.12619787746]\n",
      "9.53674316406e-07\n",
      "[-1072.0182804463752, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "1.19209289551e-06\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ". [Iter 100/300] VLB: -128469.5\n",
      "[128469.50750042961, -853.67391911332652, -127615.83358131628]\n",
      "0.0\n",
      "[-981.85333161439826, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ". [Iter 110/300] VLB: -128231.5\n",
      "[128231.49583325001, -775.79325397910725, -127455.7025792709]\n",
      "0.0\n",
      "[-745.56479926798693, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "9.53674316406e-07\n",
      ". [Iter 120/300] VLB: -127954.0\n",
      "[127954.04780413587, -638.80830309536282, -127315.23950104052]\n",
      "9.53674316406e-07\n",
      "[-648.40363821930259, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "1.19209289551e-06\n",
      ".0.0\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".1.19209289551e-06\n",
      "9.53674316406e-07\n",
      ". [Iter 130/300] VLB: -127884.7\n",
      "[127884.72987306872, -692.0823431221022, -127192.64752994661]\n",
      "0.0\n",
      "[-644.46470210113625, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "1.19209289551e-06\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "9.53674316406e-07\n",
      ".0.0\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".1.19209289551e-06\n",
      "0.0\n",
      ".9.53674316406e-07\n",
      "0.0\n",
      ". [Iter 140/300] VLB: -127697.5\n",
      "[127697.49615811913, -610.9309819483268, -127086.5651761708]\n",
      "1.19209289551e-06\n",
      "[-620.34158920996344, -182.27353906306223, -135.77063693254146, 98.0]\n",
      "9.53674316406e-07\n",
      "0.0\n",
      ".9.53674316406e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bc3493a30a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mparams_all\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mvariational_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_var_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_adam_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/optimizers.pyc\u001b[0m in \u001b[0;36madam\u001b[0;34m(grad, init_params, callback, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m      \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m  \u001b[0;31m# First  moment estimate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/util.pyc\u001b[0m in \u001b[0;36mflattened_func\u001b[0;34m(flattened_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflattened_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mflattened_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflattened_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/convenience_wrappers.pyc\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to_same_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output seems independent of input.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node, start_node)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcur_outgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mvsum\u001b[0;34m(vspace, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive_vsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprogenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogenitors\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogenitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogenitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mprimitive_vsum\u001b[0;34m(vspace, *args)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSparseObject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/numpy/numpy_extra.pyc\u001b[0m in \u001b[0;36mmut_add\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muntake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSparseObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmut_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEgCAYAAAA66k1XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD0JjfzvZXN7UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1719272d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Variational inference for matching...\")\n",
    "print(\"Initializing with MAP estimate\")\n",
    "# Global parameters\n",
    "npr.seed(0)\n",
    "\n",
    "def temperature(i):\n",
    "    tau0=0.00001\n",
    "    MIN_TEMP = 0.0001\n",
    "    ANNEAL_RATE = 0.1\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    return np_temp\n",
    "\n",
    "t = np.arange(1000)\n",
    "plt.plot(t, temperature(t))\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "\n",
    "sigma_min, sigma_max = 1e-8, 1.0\n",
    "num_adam_iters = 300\n",
    "num_mcmc_samples = 1\n",
    "indexes = np.where(M.flatten() ==1)\n",
    "\n",
    "n_params = len(indexes[0])\n",
    "\n",
    "init_mean = -10*np.ones(n_params)\n",
    "#print init_mean.shape\n",
    "print n_params\n",
    "init_logit_std = -5*npr.randn(n_params)\n",
    "init_var_params = np.concatenate([init_mean, init_logit_std])\n",
    "#print init_var_params.shape\n",
    "elbos=[]\n",
    "# SGD with Adam\n",
    "\n",
    "var_objective = lambda x,t: variational_objective(x, t, K, M)[0]\n",
    "gradient = grad(var_objective)\n",
    "elbos = []\n",
    "params_all =[]\n",
    "\n",
    "variational_params = adam(gradient, init_var_params, step_size=0.05, num_iters=num_adam_iters, callback=callback)\n",
    "\n",
    "\n",
    "# SGD with Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the elbo\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(elbos)\n",
    "plt.xlim(0, num_adam_iters)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample from the posterior and show samples\n",
    "q_mu, _, q_sigma = unpack_params(variational_params)\n",
    "\n",
    "lim = max(abs(ys).max(), abs(xs).max())\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), facecolor='white')\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        Psi_sample = q_mu + npr.randn(K - 1, K - 1) * q_sigma\n",
    "        P_sample = psi_to_birkhoff(logistic(Psi_sample / temperature(num_adam_iters)))\n",
    "        # Round doubly stochastic matrix P to the nearest permutation matrix\n",
    "        row, col = linear_sum_assignment(-P_sample)\n",
    "        \n",
    "        if (i == 0) and (j == 0):\n",
    "            col = np.argmax(P_true, axis=1)\n",
    "\n",
    "        ax = fig.add_subplot(4, 4, i*4 + j +1, frameon=True)\n",
    "        for k in range(K):\n",
    "            plt.plot(ys[k, 0], ys[k, 1], 'sk', markersize=8)\n",
    "            plt.plot(xs[k, 0], xs[k, 1], 'ok', markersize=8)\n",
    "\n",
    "        for k in range(K):\n",
    "            plt.plot(xs[k, 0], xs[k, 1], 'o',\n",
    "                     color=colors[k % len(colors)],  markersize=6)\n",
    "            plt.plot(ys[col[k], 0], ys[col[k], 1], 's',\n",
    "                     markersize=6, color=colors[k % len(colors)])\n",
    "\n",
    "        # Scale bar\n",
    "        plt.plot([lim-2*eta,lim], [-lim,-lim], '-k', lw=3)\n",
    "\n",
    "        ax.set_xlim([-1.25*lim, 1.25*lim])\n",
    "        ax.set_ylim([-1.25*lim, 1.25*lim])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        if (i==0) and (j==0):\n",
    "            ax.set_title(\"True\")\n",
    "        else:\n",
    "            ax.set_title(\"Sample {}\".format(i*4+j+1))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enumerate all possible permutations and compute their probability\n",
    "if K < 7:\n",
    "    Kfac = np.prod(np.arange(1, K+1))\n",
    "\n",
    "    post_true = {}\n",
    "    import itertools as it\n",
    "    for perm in it.permutations(np.arange(K)):\n",
    "        P = np.zeros((K, K))\n",
    "        P[np.arange(K), perm] = 1\n",
    "        post_true[perm] = log_prob(P, 0)\n",
    "\n",
    "    post_inf = {}\n",
    "    for perm in it.permutations(np.arange(K)):\n",
    "        post_inf[perm] = 0\n",
    "\n",
    "    N_sample = 1000\n",
    "    for s in range(N_sample):\n",
    "        Psi_sample = q_mu + npr.randn(K - 1, K - 1) * sigma_post\n",
    "        P_sample = psi_to_birkhoff(logistic(Psi_sample / temperature(num_adam_iters)))\n",
    "        # Round doubly stochastic matrix P to the nearest permutation matrix\n",
    "        row, col = linear_sum_assignment(-P_sample)\n",
    "        post_inf[tuple(col)] += 1\n",
    "\n",
    "    # Convert to arrays\n",
    "    post_true_vec = np.zeros(Kfac)\n",
    "    post_inf_vec = np.zeros(Kfac)\n",
    "    for i, perm in enumerate(it.permutations(np.arange(K))):\n",
    "        post_true_vec[i] = post_true[perm]\n",
    "        post_inf_vec[i] = post_inf[perm]\n",
    "\n",
    "    from scipy.misc import logsumexp\n",
    "    post_true_vec = np.exp(post_true_vec - logsumexp(post_true_vec))\n",
    "    post_inf_vec = post_inf_vec / post_inf_vec.sum()\n",
    "    sort = np.argsort(-post_true_vec)\n",
    "    post_true_vec = post_true_vec[sort]\n",
    "    post_inf_vec = post_inf_vec[sort]\n",
    "\n",
    "    trunc = 20\n",
    "    trunc_post_true_vec = np.concatenate((post_true_vec[:trunc], \n",
    "                                          [post_true_vec[trunc:].sum()]))\n",
    "\n",
    "    trunc_post_inf_vec = np.concatenate((post_inf_vec[:trunc], \n",
    "                                         [post_inf_vec[trunc:].sum()]))\n",
    "\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.bar(np.arange(trunc+1), trunc_post_true_vec, width=0.4, color=colors[0], label=\"true\")\n",
    "    plt.bar(np.arange(trunc+1)+0.4, trunc_post_inf_vec, width=0.4, color=colors[1], label=\"inf\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlim(0, trunc+1)\n",
    "\n",
    "else:\n",
    "    print(\"Can only empirically compute exact permutation probability for small K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_inf = np.zeros((K, K))\n",
    "\n",
    "N_sample = 1000\n",
    "for s in range(N_sample):\n",
    "    Psi_sample = q_mu + npr.randn(K - 1, K - 1) * q_sigma\n",
    "    B_sample = psi_to_birkhoff(logistic(Psi_sample / temperature(num_adam_iters)))\n",
    "    P_sample = birkhoff_to_perm(B_sample)\n",
    "    class_inf += P_sample\n",
    "\n",
    "class_inf /= float(N_sample)\n",
    "    \n",
    "fig = plt.figure(figsize=(6.5,2.))\n",
    "ax1 = plt.subplot(141)\n",
    "im1 = plt.imshow(P_true, interpolation=\"nearest\")\n",
    "plt.title(\"True permutation\")\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cb1 = divider.new_horizontal(size=\"5%\", pad=0.05)\n",
    "fig.add_axes(cb1)\n",
    "plt.colorbar(im1, cax=cb1)\n",
    "\n",
    "ax2 = plt.subplot(142)\n",
    "im2 = plt.imshow(P_map, interpolation=\"nearest\")\n",
    "plt.title(\"MAP Permutation\")\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cb2 = divider.new_horizontal(size=\"5%\", pad=0.05)\n",
    "fig.add_axes(cb2)\n",
    "plt.colorbar(im2, cax=cb2)\n",
    "\n",
    "ax3 = plt.subplot(143)\n",
    "im3 = plt.imshow(class_inf, vmin=0, vmax=1, interpolation=\"nearest\")\n",
    "ax3.set_title(\"$\\mathrm{E}_{q(P)}[\\mathrm{round}(P)]$\")\n",
    "\n",
    "divider = make_axes_locatable(ax3)\n",
    "cb3 = divider.new_horizontal(size=\"5%\", pad=0.05)\n",
    "fig.add_axes(cb3)\n",
    "plt.colorbar(im3, cax=cb3)\n",
    "\n",
    "ax4 = plt.subplot(144)\n",
    "im4 = plt.imshow(np.exp(score), interpolation=\"nearest\",cmap=\"Blues\")\n",
    "ax4.set_title(\"$p(y_j \\\\mid x_i, \\\\eta)$\")\n",
    "\n",
    "divider = make_axes_locatable(ax4)\n",
    "cb4 = divider.new_horizontal(size=\"5%\", pad=0.05)\n",
    "fig.add_axes(cb4)\n",
    "plt.colorbar(im4, cax=cb4)\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.savefig(\"matching.pdf\")\n",
    "plt.savefig(\"matching.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(q_mu, interpolation=\"none\", \n",
    "           vmin=-abs(q_mu).max(), \n",
    "           vmax=abs(q_mu).max(), \n",
    "           cmap=\"RdBu\")\n",
    "plt.title(\"q mean\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(q_sigma, interpolation=\"none\")\n",
    "plt.title(\"q variance\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"log p(y | x, P_{true}):       \", log_prob(P_true, 0))\n",
    "print(\"log p(y | x, P_{map}):        \", log_prob(P_map, 0))\n",
    "\n",
    "q_probs = []\n",
    "for s in range(N_sample):\n",
    "    Psi_sample = q_mu + npr.randn(K - 1, K - 1) * q_sigma\n",
    "    B_sample = psi_to_birkhoff(logistic(Psi_sample / temperature(num_adam_iters)))\n",
    "    P_sample = birkhoff_to_perm(B_sample)\n",
    "    q_probs.append(log_prob(P_sample, 0))\n",
    "q_probs = np.array(q_probs)\n",
    "\n",
    "print(\"log E_{q(P)} [p(y | x, P)]:   \", -np.log(N_sample) + logsumexp(q_probs))\n",
    "print(\"min_{P~q(P)} log p(y | x, P): \", np.min(q_probs))\n",
    "print(\"max_{P~q(P)} log p(y | x, P): \", np.max(q_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(q_probs / K**2, 40, color=colors[1], label=\"P ~ q(P)\")\n",
    "yl = plt.ylim()\n",
    "plt.plot(log_prob(P_true, 0) / K**2 * np.ones(2), yl, \n",
    "         c=colors[0], label=\"P_true\")\n",
    "plt.plot(log_prob(P_map, 0) / K**2 * np.ones(2), yl, \n",
    "         c=colors[2], label=\"P_MAP\")\n",
    "plt.ylim(yl)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"$\\\\mathrm{log} \\; p(y | x, P) / K^2 $\")\n",
    "plt.ylabel(\"count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
