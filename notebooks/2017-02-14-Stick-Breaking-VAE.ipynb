{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for stick-breaking gaussian vs concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/birkhoff/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/')\n",
    "import numpy as np\n",
    "\n",
    "import categorical as cat\n",
    "%matplotlib inline\n",
    "slim=tf.contrib.slim\n",
    "Bernoulli = tf.contrib.distributions.Bernoulli\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create gaussian-stick-breaking-sigmoid related functions(more generally, any stick-breaking reparametrizable one)\n",
    "def psi_to_pi(psi):\n",
    "    #return tf.cumsum(tf.log(1-psi), axis=1)\n",
    "    #print psi.get_shape()[0]\n",
    "    log1 = tf.concat(1, [ tf.log(psi), tf.zeros((tf.shape(psi)[0],1))])\n",
    "    log2 = tf.cumsum(tf.concat(1, [ tf.zeros((tf.shape(psi)[0],1)), tf.log(1-psi) ]) ,axis=1)\n",
    "    return tf.exp(log2+log1)\n",
    "\n",
    "def sample_pi_from_gaussian(params, temperature, eps=1e-15):\n",
    "    mu, logit_sigma = tf.split(1, 2, params) \n",
    "    #log_s = tf.maximum(tf.minimum(log_std,10),-10)\n",
    "    sigma_min= 1e-9\n",
    "    sigma_max= 2\n",
    "    sigma = sigma_min +(sigma_max-sigma_min)*tf.sigmoid(logit_sigma)\n",
    "    sample = (mu + sigma * tf.random_normal(tf.shape(mu), mean=0.0, stddev=1.0)) / temperature \n",
    "    psi =  tf.maximum(tf.minimum(tf.sigmoid(sample), 1-eps), eps)\n",
    "    return (sample,psi,psi_to_pi(psi))\n",
    "\n",
    "def log_density_pi_gaussian(sample, params, temperature, eps=1e-15):\n",
    "    mu, logit_sigma = tf.split(1, 2, params)\n",
    "    K = tf.shape(sample)[1]+1\n",
    "    N = tf.shape(sample)[0]\n",
    "    sigma_min= 1e-9\n",
    "    sigma_max= 2\n",
    "    sigma = sigma_min +(sigma_max-sigma_min)*tf.sigmoid(logit_sigma) / temperature\n",
    "    \n",
    "    var =  tf.pow(sigma, 2.0) / tf.pow(temperature, 2.0)\n",
    "    psi = tf.maximum(tf.minimum(tf.sigmoid(sample), 1-eps), eps)\n",
    "    seq = tf.cast(tf.tile(tf.reshape(tf.range(K-2,0,-1),[1,-1]),[N,1]),dtype=tf.float32)\n",
    "    return  -tf.reduce_sum(tf.multiply(seq, tf.log(1 - tf.slice(psi,[0,0],[N,K-2]))), axis=1) + tf.reduce_sum(-0.5 * tf.div(tf.pow(sample-mu / temperature, 2.0), var)  - 0.5 * tf.log(2*np.pi) - 0.5* tf.log(var) , axis=1) \\\n",
    "       + tf.reduce_sum(-tf.log(psi) - tf.log(1-psi), axis=1) \n",
    "    #return tf.reduce_sum(tf.div(tf.pow(sample-mu, 2.0), var)   , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gumbel-related function\n",
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "    return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(tf.shape(logits))\n",
    "    return tf.nn.softmax( y / temperature)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "    return y\n",
    "\n",
    "def log_density_pi_concrete(pi,params,temperature):\n",
    "    K=tf.cast(tf.shape(pi)[1],dtype=tf.float32)\n",
    "    return -tf.log(tf.reduce_sum(tf.pow(pi, -temperature) * tf.exp(params), axis=1)) * K  \\\n",
    "    + tf.reduce_sum(params + (-temperature - 1) * tf.log(pi), axis=1) + (K - 1) * tf.log(temperature) + tf.lgamma(K+0.0)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K=10 # number of classes\n",
    "N=30 # number of categorical distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create gaussian VAE\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "params = tf.reshape(slim.fully_connected(net,2*(K-1)*N,activation_fn=None),[-1,2*(K-1)])\n",
    "\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    " \n",
    "sample,psi,pi = sample_pi_from_gaussian(params,tau)\n",
    "z = tf.reshape(pi,[-1,N,K])\n",
    "\n",
    "log_dens=log_density_pi_gaussian(sample, params, tau)\n",
    "\n",
    "net = slim.stack(slim.flatten(z),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "p_x = Bernoulli(logits=logits_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input image x (shape=(batch_size,784))\n",
    "\n",
    "#Debug Gaussian VAE: verify the outputs by tensorflow code are the same as in categorical.py\n",
    "# variational posterior q(y|x), i.e. the encoder (shape=(batch_size,200))\n",
    "#x = tf.placeholder(tf.float32,[None,784])\n",
    "#net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "K=5\n",
    "N=1000\n",
    "params = tf.concat(1, [ -1*tf.ones((1000,K-1)), 0*tf.ones((1000,K-1)) ]) \n",
    "tau = tf.Variable(1.0,name=\"temperature\")\n",
    "with tf.Session() as sess:\n",
    "    sample,psi,pi = sample_pi_from_gaussian(params,tau)\n",
    "    log_dens=log_density_pi_gaussian(sample, params, tau)\n",
    "    np_sample=sess.run(sample,feed_dict={tau:1})\n",
    "    np_log_dens=sess.run(log_dens,feed_dict={tau:1})\n",
    "    np_pi=sess.run(pi,feed_dict={tau:1})\n",
    "    np_psi = sess.run(psi,feed_dict={tau:1})\n",
    "    np_params = sess.run(params,feed_dict={tau:1})\n",
    "    print np.mean(np_log_dens)\n",
    "    print np.mean(cat.log_density_gaussian_psi(np_sample, np_params, 0,10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create gumbell VAE\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "params = tf.reshape(slim.fully_connected(net,K*N,activation_fn=None),[-1,K])\n",
    "\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    " \n",
    "pi = gumbel_softmax_sample(params,tau)\n",
    "z = tf.reshape(pi,[-1,N,K])\n",
    "\n",
    "log_dens=log_density_pi_concrete(pi, params, tau)\n",
    "\n",
    "net = slim.stack(slim.flatten(z),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "p_x = Bernoulli(logits=logits_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Debug Gumbell\n",
    "K=5\n",
    "N=100000\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    "params = -1*tf.ones((N,K))\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    pi = gumbel_softmax_sample(params,tau)\n",
    "    log_dens=log_density_pi_concrete(pi, params, tau)\n",
    "    np_sample=sess.run(pi,feed_dict={tau:1})\n",
    "    np_log_dens=sess.run(log_dens,feed_dict={tau:1})\n",
    "    np_pi=sess.run(pi,feed_dict={tau:1})\n",
    "   \n",
    "    np_params = sess.run(params,feed_dict={tau:1})\n",
    "    \n",
    "    print np.mean(np_log_dens)\n",
    "    print np.mean(cat.log_density_pi_concrete(np_sample, np_params, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss and train ops (Run either the gumbel or the gaussian for now)\n",
    "kl_tmp = tf.reshape((log_dens+tf.lgamma(K+0.0)),[-1,N])\n",
    "KL = tf.reduce_sum(kl_tmp,1)\n",
    "elbo=tf.reduce_sum(p_x.log_prob(x),1) - KL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-db15cc133fe7>:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-db15cc133fe7>:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "loss=tf.reduce_mean(-elbo)\n",
    "lr=tf.constant(0.001)\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,var_list=slim.get_model_variables())\n",
    "init_op=tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data = input_data.read_data_sets('/tmp/', one_hot=True).train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=100\n",
    "NUM_ITERS=200\n",
    "tau0=1.0 # initial temperature\n",
    "np_temp=tau0\n",
    "np_lr=0.001\n",
    "ANNEAL_RATE=0.00003\n",
    "MIN_TEMP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, ELBO: -1412.705\n",
      "Step 11, ELBO: -1174.455\n",
      "Step 21, ELBO: -1084.537\n",
      "Step 31, ELBO: -1092.381\n",
      "Step 41, ELBO: -1075.355\n",
      "Step 51, ELBO: -1073.973\n",
      "Step 61, ELBO: -1076.603\n",
      "Step 71, ELBO: -1070.497\n",
      "Step 81, ELBO: -1088.307\n",
      "Step 91, ELBO: -1091.449\n",
      "Step 101, ELBO: -1068.103\n",
      "Step 111, ELBO: -1071.765\n",
      "Step 121, ELBO: -1067.802\n",
      "Step 131, ELBO: -1063.069\n",
      "Step 141, ELBO: -1062.998\n",
      "Step 151, ELBO: -1087.623\n",
      "Step 161, ELBO: -1066.692\n",
      "Step 171, ELBO: -1083.626\n",
      "Step 181, ELBO: -1088.090\n",
      "Step 191, ELBO: -1069.358\n"
     ]
    }
   ],
   "source": [
    "dat=[]\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "for i in range(1,NUM_ITERS):\n",
    "  np_x,np_y=data.next_batch(BATCH_SIZE)\n",
    "  _,np_loss=sess.run([train_op,loss],{\n",
    "      x:np_x,\n",
    "      tau:np_temp,\n",
    "      lr:np_lr\n",
    "    })\n",
    "  if i % 100 == 1:\n",
    "    dat.append([i,np_temp,np_loss])\n",
    "  if i % 1000 == 1:\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    np_lr*=0.9\n",
    "  if i % 10 == 1:\n",
    "      print('Step %d, ELBO: %0.3f' % (i,-np_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
