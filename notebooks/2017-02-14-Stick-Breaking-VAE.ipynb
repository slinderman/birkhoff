{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for stick-breaking gaussian vs concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.07232658e+01  -2.07232658e+01  -2.07232658e+01 ...,  -1.60425682e+01\n",
      "   -2.07232658e+01  -6.25831864e+00]\n",
      " [ -2.07232658e+01  -2.07232658e+01  -2.07232658e+01 ...,  -1.37222759e-05\n",
      "   -2.07232658e+01  -1.11964969e+01]\n",
      " [ -2.07232658e+01  -2.07232658e+01  -2.07232658e+01 ...,  -2.07232658e+01\n",
      "   -9.99999972e-10  -2.07232658e+01]\n",
      " ..., \n",
      " [ -2.07232658e+01  -2.07232658e+01  -2.07232658e+01 ...,  -2.07232658e+01\n",
      "   -2.07232658e+01  -1.11826596e+01]\n",
      " [ -2.07232658e+01  -2.07232658e+01  -2.07232658e+01 ...,  -2.07232658e+01\n",
      "   -2.07232658e+01  -2.07232658e+01]\n",
      " [ -2.07232658e+01  -2.07232658e+01  -9.43282997e+00 ...,  -2.07232658e+01\n",
      "   -2.07232658e+01  -2.07232658e+01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/birkhoff/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/')\n",
    "import numpy as np\n",
    "\n",
    "import categorical as cat\n",
    "%matplotlib inline\n",
    "slim=tf.contrib.slim\n",
    "Bernoulli = tf.contrib.distributions.Bernoulli\n",
    "Dirichlet = tf.contrib.distributions.Dirichlet\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create gaussian-stick-breaking-sigmoid related functions(more generally, any stick-breaking reparametrizable one)\n",
    "def psi_to_pi(psi):\n",
    "    #return tf.cumsum(tf.log(1-psi), axis=1)\n",
    "    #print psi.get_shape()[0]\n",
    "    log1 = tf.concat(1, [ tf.log(psi), tf.zeros((tf.shape(psi)[0],1))])\n",
    "    log2 = tf.cumsum(tf.concat(1, [ tf.zeros((tf.shape(psi)[0],1)), tf.log(1-psi) ]) ,axis=1)\n",
    "    return tf.exp(log2+log1)\n",
    "\n",
    "def sample_pi_from_gaussian(params, temperature, eps=1e-9):\n",
    "    logit_mu, logit_sigma = tf.split(1, 2, params) \n",
    "    #log_s = tf.maximum(tf.minimum(log_std,10),-10)\n",
    "    sigma_min= 1e-9\n",
    "    sigma_max= 5\n",
    "    mu_min = -5\n",
    "    mu_max = 5\n",
    "    mu = mu_min +(mu_max-mu_min)*tf.sigmoid(logit_mu)\n",
    "    sigma = sigma_min +(sigma_max-sigma_min)*tf.sigmoid(logit_sigma)\n",
    "    sample = (mu + sigma * tf.random_normal(tf.shape(mu), mean=0.0, stddev=1.0)) / temperature \n",
    "    psi =  (eps) +(1-2*eps)*tf.sigmoid(sample)\n",
    "    return (sample,psi,psi_to_pi(psi))\n",
    "\n",
    "def log_density_pi_gaussian(sample, params, temperature, eps=1e-9):\n",
    "    logit_mu, logit_sigma = tf.split(1, 2, params)\n",
    "    K = tf.shape(sample)[1]+1\n",
    "    N = tf.shape(sample)[0]\n",
    "    sigma_min= 1e-9\n",
    "    sigma_max= 5\n",
    "    mu_min = -5\n",
    "    mu_max = 5\n",
    "    mu = mu_min +(mu_max-mu_min)*tf.sigmoid(logit_mu)\n",
    "\n",
    "    sigma = sigma_min +(sigma_max-sigma_min)*tf.sigmoid(logit_sigma) / temperature\n",
    "    \n",
    "    var =  tf.pow(sigma, 2.0) / tf.pow(temperature, 2.0)\n",
    "    psi =  (eps) +(1-2*eps) * tf.sigmoid(sample)\n",
    "    seq = tf.cast(tf.tile(tf.reshape(tf.range(K-2,0,-1),[1,-1]),[N,1]),dtype=tf.float32)\n",
    "    return  -tf.reduce_sum(tf.multiply(seq, tf.log(1 - tf.slice(psi,[0,0],[N,K-2]))), axis=1) + tf.reduce_sum(-0.5 * tf.div(tf.pow(sample-mu / temperature, 2.0), var)  - 0.5 * tf.log(2*np.pi) - 0.5* tf.log(var) , axis=1) \\\n",
    "       + tf.reduce_sum(-tf.log(psi) - tf.log(1-psi), axis=1) \n",
    "    #return tf.reduce_sum(tf.div(tf.pow(sample-mu, 2.0), var)   , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gumbel-related function\n",
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "    return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(tf.shape(logits))\n",
    "    return tf.nn.softmax( y / temperature)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "    return y\n",
    "\n",
    "def log_density_pi_concrete(pi,params,temperature):\n",
    "    K=tf.cast(tf.shape(pi)[1],dtype=tf.float32)\n",
    "    return -tf.log(tf.reduce_sum(tf.pow(pi, -temperature) * tf.exp(params), axis=1)) * K  \\\n",
    "    + tf.reduce_sum(params + (-temperature - 1) * tf.log(pi), axis=1) + (K - 1) * tf.log(temperature) + tf.lgamma(K+0.0)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K=5 # number of classes\n",
    "N=10 # number of categorical distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha=0.3\n",
    "# Create gaussian VAE\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "params = tf.reshape(slim.fully_connected(net,2*(K-1)*N,activation_fn=None),[-1,2*(K-1)])\n",
    "\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    " \n",
    "sample,psi,pi = sample_pi_from_gaussian(params,tau)\n",
    "z = tf.reshape(pi,[-1,N,K])\n",
    "\n",
    "log_dens=log_density_pi_gaussian(sample, params, tau)\n",
    "\n",
    "net = slim.stack(slim.flatten(z),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "p_x = Bernoulli(logits=logits_x)\n",
    "p_z = Dirichlet(tf.ones(K)*alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input image x (shape=(batch_size,784))\n",
    "\n",
    "#Debug Gaussian VAE: verify the outputs by tensorflow code are the same as in categorical.py\n",
    "# variational posterior q(y|x), i.e. the encoder (shape=(batch_size,200))\n",
    "#x = tf.placeholder(tf.float32,[None,784])\n",
    "#net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "K=5\n",
    "N=1000\n",
    "params = tf.concat(1, [ -1*tf.ones((1000,K-1)), 0*tf.ones((1000,K-1)) ]) \n",
    "tau = tf.Variable(1.0,name=\"temperature\")\n",
    "with tf.Session() as sess:\n",
    "    sample,psi,pi = sample_pi_from_gaussian(params,tau)\n",
    "    log_dens=log_density_pi_gaussian(sample, params, tau)\n",
    "    np_sample=sess.run(sample,feed_dict={tau:1})\n",
    "    np_log_dens=sess.run(log_dens,feed_dict={tau:1})\n",
    "    np_pi=sess.run(pi,feed_dict={tau:1})\n",
    "    np_psi = sess.run(psi,feed_dict={tau:1})\n",
    "    np_params = sess.run(params,feed_dict={tau:1})\n",
    "    print np.mean(np_log_dens)\n",
    "    print np.mean(cat.log_density_gaussian_psi(np_sample, np_params, 0,10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create gumbell VAE\n",
    "alpha=1\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "params = tf.reshape(slim.fully_connected(net,K*N,activation_fn=None),[-1,K])\n",
    "\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    " \n",
    "pi = gumbel_softmax_sample(params,tau)\n",
    "z = tf.reshape(pi,[-1,N,K])\n",
    "\n",
    "log_dens=log_density_pi_concrete(pi, params, tau)\n",
    "\n",
    "net = slim.stack(slim.flatten(z),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "p_x = Bernoulli(logits=logits_x)\n",
    "p_z = Dirichlet(tf.ones(K)*alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Debug Gumbell\n",
    "K=5\n",
    "N=100000\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    "params = -1*tf.ones((N,K))\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    pi = gumbel_softmax_sample(params,tau)\n",
    "    log_dens=log_density_pi_concrete(pi, params, tau)\n",
    "    np_sample=sess.run(pi,feed_dict={tau:1})\n",
    "    np_log_dens=sess.run(log_dens,feed_dict={tau:1})\n",
    "    np_pi=sess.run(pi,feed_dict={tau:1})\n",
    "   \n",
    "    np_params = sess.run(params,feed_dict={tau:1})\n",
    "    \n",
    "    print np.mean(np_log_dens)\n",
    "    print np.mean(cat.log_density_pi_concrete(np_sample, np_params, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss and train ops (Run either the gumbel or the gaussian for now)\n",
    "#kl_tmp = tf.reshape((log_dens+tf.lgamma(K+0.0)),[-1,N])\n",
    "kl_tmp = tf.reshape((log_dens-p_z.log_prob(pi)),[-1,N])\n",
    "KL = tf.reduce_sum(kl_tmp,1)\n",
    "elbo=tf.reduce_sum(p_x.log_prob(x),1) - KL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-db15cc133fe7>:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-db15cc133fe7>:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "loss=tf.reduce_mean(-elbo)\n",
    "lr=tf.constant(0.001)\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,var_list=slim.get_model_variables())\n",
    "init_op=tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data = input_data.read_data_sets('/tmp/', one_hot=True).train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=100\n",
    "NUM_ITERS=14\n",
    "tau0=1.0 # initial temperature\n",
    "np_temp=tau0\n",
    "np_lr=0.001\n",
    "ANNEAL_RATE=0.00003\n",
    "MIN_TEMP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, ELBO: -562.205\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d98e9867a614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step %d, ELBO: %0.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dat=[]\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "for i in range(1,NUM_ITERS):\n",
    "  np_x,np_y=data.next_batch(BATCH_SIZE)\n",
    "  _,np_loss,np_log_dens,np_sample,np_logits_x,np_pi,np_params,np_px_logx=sess.run([train_op,loss,log_dens,sample,logits_x,\n",
    "                                                                        pi,params,p_x.log_prob(x)],{\n",
    "      x:np_x,\n",
    "      tau:np_temp,\n",
    "      lr:np_lr\n",
    "    })\n",
    "  if i % 100 == 1:\n",
    "    dat.append([i,np_temp,np_loss])\n",
    "  if i % 1000 == 1:\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    np_lr*=0.9\n",
    "  if i % 2 == 1:\n",
    "      print('Step %d, ELBO: %0.3f' % (i,-np_loss)) \n",
    "  assert np.isnan(np_loss) is False  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " ..., \n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print np.isnan(np_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_x1,_=data.next_batch(100)\n",
    "np_x2,np_y1 = sess.run([p_x.mean(),z],{x:np_x1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_anim(data,figsize,filename):\n",
    "  fig=plt.figure(figsize=(figsize[1]/10.0,figsize[0]/10.0))\n",
    "  im = plt.imshow(data[0].reshape(figsize),cmap=plt.cm.gray,interpolation='none')\n",
    "  plt.gca().set_axis_off()\n",
    "  #fig.tight_layout()\n",
    "  fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "  def updatefig(t):\n",
    "    im.set_array(data[t].reshape(figsize))\n",
    "    return im,\n",
    "  anim=animation.FuncAnimation(fig, updatefig, frames=100, interval=50, blit=True, repeat=True)\n",
    "  Writer = animation.writers['imagemagick']\n",
    "  writer = Writer(fps=1, metadata=dict(artist='Me'), bitrate=1800)\n",
    "  anim.save(filename, writer=writer)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=np.array(dat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2)\n",
    "axarr[0].plot(dat[0],dat[1])\n",
    "axarr[0].set_ylabel('Temperature')\n",
    "axarr[1].plot(dat[0],dat[2])\n",
    "axarr[1].set_ylabel('-ELBO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M=100*N\n",
    "np_y = np.zeros((M,K))\n",
    "np_y[range(M),np.random.choice(K,M)] = 1\n",
    "np_y = np.reshape(np_y,[100,N,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_p=p_x.mean()\n",
    "np_x= sess.run(x_p,{z:np_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_y = np_y.reshape((10,10,N,K))\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=0),axis=3)\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=1),axis=2)\n",
    "y_img = np.squeeze(np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_x = np_x.reshape((10,10,28,28))\n",
    "# split into 10 (1,10,28,28) images, concat along columns -> 1,10,28,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=0),axis=3)\n",
    "# split into 10 (1,1,28,280) images, concat along rows -> 1,1,280,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=1),axis=2)\n",
    "x_img = np.squeeze(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2,figsize=(15,15))\n",
    "# samples\n",
    "axarr[0].matshow(y_img,cmap=plt.cm.gray)\n",
    "axarr[0].set_title('Z Samples')\n",
    "# reconstruction\n",
    "axarr[1].imshow(x_img,cmap=plt.cm.gray,interpolation='none')\n",
    "axarr[1].set_title('Generated Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.tight_layout()\n",
    "f.savefig('Gaussian-Cont.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
