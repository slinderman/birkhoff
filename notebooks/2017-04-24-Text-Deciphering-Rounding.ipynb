{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/birkhoff/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/src/')\n",
    "sys.path.append('/Users/Cybele/GIT/birkhoff/')\n",
    "\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as scipy\n",
    "from autograd import grad\n",
    "from autograd.optimizers import adam,sgd\n",
    "from autograd.scipy.misc import logsumexp\n",
    "from birkhoff.primitives import birkhoff_to_perm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is not very important: just define the methods for trimming and process the text\n",
    "\n",
    "n_alph_car=26\n",
    "# This function takes as input a decryption key and creates a dict for key where each letter in the decryption key\n",
    "# maps to a alphabet For example if the decryption key is \"DGHJKL....\" this function will create a dict like {D:A,G:B,H:C....} \n",
    "def create_cipher_dict(cipher):\n",
    "    cipher_dict = {}\n",
    "    alphabet_list = list(string.ascii_uppercase[:n_alph_car])\n",
    "    for i in range(len(cipher)):\n",
    "        cipher_dict[alphabet_list[i]] = cipher[i]\n",
    "    return cipher_dict\n",
    "\n",
    "\n",
    "# This function takes a text and applies the cipher/key on the text and returns text.\n",
    "def apply_cipher_on_text(text, cipher):\n",
    "    cipher_dict = create_cipher_dict(cipher)\n",
    "    text = list(text)\n",
    "    newtext = \"\"\n",
    "    for elem in text:\n",
    "        if elem.upper() in cipher_dict:\n",
    "            newtext += cipher_dict[elem.upper()]\n",
    "        else:\n",
    "            newtext += \" \"\n",
    "    return newtext\n",
    "\n",
    "\n",
    "# This function takes as input a path to a long text and creates scoring_params dict which contains the\n",
    "# number of time each pair of alphabet appears together\n",
    "# Ex. {'AB':234,'TH':2343,'CD':23 ..}\n",
    "def create_scoring_params_dict(longtext_path):\n",
    "    scoring_params = {}\n",
    "    alphabet_list = list(string.ascii_uppercase[:n_alph_car])\n",
    "    with open(longtext_path) as fp:\n",
    "        for line in fp:\n",
    "            data = list(line.strip())\n",
    "            for i in range(len(data) - 1):\n",
    "                alpha_i = data[i].upper()\n",
    "                alpha_j = data[i + 1].upper()\n",
    "                if alpha_i not in alphabet_list and alpha_i != \" \":\n",
    "                    alpha_i = \" \"\n",
    "                if alpha_j not in alphabet_list and alpha_j != \" \":\n",
    "                    alpha_j = \" \"\n",
    "                key = alpha_i + alpha_j\n",
    "                if key in scoring_params:\n",
    "                    scoring_params[key] += 1\n",
    "                else:\n",
    "                    scoring_params[key] = 1\n",
    "    return scoring_params\n",
    "\n",
    "\n",
    "def score_params_on_cipher(text):\n",
    "    scoring_params = {}\n",
    "    alphabet_list = list(string.ascii_uppercase[:n_alph_car])\n",
    "    data = list(text.strip())\n",
    "    for i in range(len(data) - 1):\n",
    "        alpha_i = data[i].upper()\n",
    "        alpha_j = data[i + 1].upper()\n",
    "        if alpha_i not in alphabet_list and alpha_i != \" \":\n",
    "            alpha_i = \" \"\n",
    "        if alpha_j not in alphabet_list and alpha_j != \" \":\n",
    "            alpha_j = \" \"\n",
    "        key = alpha_i + alpha_j\n",
    "        if key in scoring_params:\n",
    "            scoring_params[key] += 1\n",
    "        else:\n",
    "            scoring_params[key] = 1\n",
    "    return scoring_params\n",
    "\n",
    "\n",
    "# This function takes the text to be decrypted and a cipher to score the cipher.\n",
    "# This function returns the log(score) metric\n",
    "\n",
    "def get_cipher_score(text, cipher, scoring_params):\n",
    "    cipher_dict = create_cipher_dict(cipher)\n",
    "    decrypted_text = apply_cipher_on_text(text, cipher)\n",
    "    scored_f = score_params_on_cipher(decrypted_text)\n",
    "    cipher_score = 0\n",
    "    for k, v in scored_f.iteritems():\n",
    "        if k in scoring_params:\n",
    "            cipher_score += v * math.log(scoring_params[k])\n",
    "    return cipher_score\n",
    "\n",
    "\n",
    "# Generate a proposal cipher by swapping letters at two random location\n",
    "def generate_cipher(cipher):\n",
    "    pos1 = random.randint(0, len(list(cipher)) - 1)\n",
    "    pos2 = random.randint(0, len(list(cipher)) - 1)\n",
    "    if pos1 == pos2:\n",
    "        return generate_cipher(cipher)\n",
    "    else:\n",
    "        cipher = list(cipher)\n",
    "        pos1_alpha = cipher[pos1]\n",
    "        pos2_alpha = cipher[pos2]\n",
    "        cipher[pos1] = pos2_alpha\n",
    "        cipher[pos2] = pos1_alpha\n",
    "        return \"\".join(cipher)\n",
    "\n",
    "\n",
    "# Toss a random coin with robability of head p. If coin comes head return true else false.\n",
    "def random_coin(p):\n",
    "    unif = random.uniform(0, 1)\n",
    "    if unif >= p:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also\n",
    "# the last few states \n",
    "def MCMC_decrypt(n_iter, cipher_text, scoring_params):\n",
    "    current_cipher = string.ascii_uppercase  # Generate a random cipher to start\n",
    "    state_keeper = set()\n",
    "    best_state = ''\n",
    "    score = 0\n",
    "    for i in range(n_iter):\n",
    "        state_keeper.add(current_cipher)\n",
    "        proposed_cipher = generate_cipher(current_cipher)\n",
    "        score_current_cipher = get_cipher_score(cipher_text, current_cipher, scoring_params)\n",
    "        score_proposed_cipher = get_cipher_score(cipher_text, proposed_cipher, scoring_params)\n",
    "        acceptance_probability = min(1, math.exp(score_proposed_cipher - score_current_cipher))\n",
    "        if score_current_cipher > score:\n",
    "            best_state = current_cipher\n",
    "        if random_coin(acceptance_probability):\n",
    "            current_cipher = proposed_cipher\n",
    "        if i % 500 == 0:\n",
    "            print \"iter\", i, \":\", apply_cipher_on_text(cipher_text, current_cipher)[0:99]\n",
    "    return state_keeper, best_state\n",
    "\n",
    "\n",
    "## Run the Main Program:\n",
    "\n",
    "scoring_params = create_scoring_params_dict('/Users/Cybele/GIT/MCMC-Cipher-Solver/war_and_peace.txt')\n",
    "\n",
    "def trimm_text(alphabet_list, text):\n",
    "    text_trimmed = ''\n",
    "    for i in range(len(text)):\n",
    "        if text[i].upper() in alphabet_list:\n",
    "            text_trimmed +=text[i].upper()\n",
    "    return text_trimmed\n",
    "\n",
    "def calculate_N_from_text(alphabet_list, trimmed_text):\n",
    "    K = len(alphabet_list)\n",
    "    N = np.zeros((K , K))\n",
    "    for i in range(len(trimmed_text)-1):\n",
    "        if trimmed_text[i].upper() in alphabet_list and trimmed_text[i+1].upper() in alphabet_list:\n",
    "            i0=alphabet_list.index(trimmed_text[i].upper())\n",
    "            i1=alphabet_list.index(trimmed_text[i+1].upper())\n",
    "            N[i0,i1]+=1\n",
    "    return N\n",
    "\n",
    "\n",
    "def decipher_text(alphabet_list, perm,text):\n",
    "    str_final =''\n",
    "    for t in text:\n",
    "        \n",
    "        ind = alphabet_list.index(t.upper())\n",
    "        ind_perm = np.where(perm == ind)[0][0]\n",
    "        str_final += alphabet_list[ind_perm]\n",
    "    return str_final\n",
    "\n",
    "def cipher_text(alphabet_list, perm,text):\n",
    "    str_final =''\n",
    "    for t in text:\n",
    "        ind = alphabet_list.index(t.upper())\n",
    "        ind_perm = perm[ind]\n",
    "        str_final += alphabet_list[ind_perm]\n",
    "    return str_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define text\n",
    "plain_text = \"As Oliver gave this first proof of the free and proper action of his lungs, \\\n",
    "the patchwork coverlet which was carelessly flung over the iron bedstead, rustled; \\\n",
    "the pale face of a young woman was raised feebly from the pillow; and a faint voice imperfectly \\\n",
    "articulated the words, Let me see the child, and die. \\\n",
    "The surgeon had been sitting with his face turned towards the fire: giving the palms of his hands a warm \\\n",
    "and a rub alternately. As the young woman spoke, he rose, and advancing to the bed's head, said, with more kindness \\\n",
    "than might have been expected of him In the beginning was the Word, and the Word was with God, and the Word was God. \\\n",
    "He was with God in the beginning. Through him all things were made; without him nothing was made \\\n",
    "that has been made. In him was life, and that life was the light of all mankind. The light shines in the darkness, \\\n",
    "and the darkness has not overcome it. There was a man sent from God whose name was John. He came as a witness \\\n",
    "to testify concerning that light, so that through him all might believe. He himself was not the light; he came \\\n",
    "only as a witness to the light. The true light that gives light to everyone was coming into the world. \\\n",
    "He was in the world, and though the world was made through him, the world did not recognize him.\\\n",
    "He came to that which was his own, but his own did not receive him.  Yet to all who did receive him, to those who believed \\\n",
    "in his name, he gave the right to become children of God children born not of natural descent, \\\n",
    "nor of human decision or a husbandâ€™s will, but born of God.\\\n",
    "What we think, or what we know, or what we believe is, in the end, of little consequence. The only consequence is what we do\\\n",
    "The jour printer with gray head and gaunt jaws works at his case,\\\n",
    "He turns his quid of tobacco while his eyes blurr with the manu\\\n",
    "script\"\n",
    "\n",
    "\n",
    "\n",
    "alphabet_list = list(string.ascii_uppercase[:n_alph_car]) + [' ']\n",
    "\n",
    "K = len(alphabet_list) # Number of characters in alphabet + space\n",
    "\n",
    "log_M = np.zeros((K, K )) # matrix with observed (as the text is large, convergeces to 'true')  \\\n",
    "                          # log transition probabilities of characters in originalt text (war and peace)\n",
    "\n",
    "for key in scoring_params:\n",
    "    i0 = alphabet_list.index(key[0])\n",
    "    i1 = alphabet_list.index(key[1])\n",
    "    log_M[i0,i1] = np.log(scoring_params[key])\n",
    "\n",
    "\n",
    "N = np.zeros((K, K)) # matrix with observed transitions in (trimmed) plain_text\n",
    "\n",
    "text_trimmed = trimm_text(alphabet_list,plain_text)\n",
    "\n",
    "perm_true = np.random.choice(range(K), K ,replace = False) # define a random permutation\n",
    "#perm_true = range(K)\n",
    "P_true = np.zeros((K, K))\n",
    "P_true[np.arange(K), perm_true] = 1\n",
    "\n",
    "ciphered_text =cipher_text(alphabet_list, perm_true, text_trimmed)\n",
    "N = calculate_N_from_text(alphabet_list, ciphered_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here, the Revelant functions\n",
    "\n",
    "def logistic(psi): return np.exp(psi)/(1+np.exp(psi))\n",
    "\n",
    "def round_to_perm(P):\n",
    "    \"\"\" Rounds matrix P to its closest permutation, using the slow hungarian\"\"\"\n",
    "    \n",
    "    K = P.shape[0]\n",
    "    \n",
    "    assert P.shape == (K, K)\n",
    "    row, col = linear_sum_assignment(-P)\n",
    "    P = np.zeros((K, K))\n",
    "    P[row, col] = 1.0\n",
    "    return P\n",
    "\n",
    "def unpack_params_sparse(params, K, M):\n",
    "    \"\"\"Unpacks params in the sparse matrices logit_mu, logit_sigma, with sparsity pattern given by M. It could be improved\n",
    "     by avoiding the for\"\"\"\n",
    "\n",
    "    indexes = np.where(M.flatten() == 1)\n",
    "    logit_mu = []\n",
    "    logit_sigma = []\n",
    "    \n",
    "    cont = 0\n",
    "    \n",
    "    for i in range(K*K):\n",
    "        if i in indexes[0]:\n",
    "            logit_mu.append(params[:n_params][cont])\n",
    "            logit_sigma.append(params[n_params:][cont])\n",
    "            cont+=1\n",
    "        else:\n",
    "            logit_mu.append(0)\n",
    "            logit_sigma.append(1)\n",
    "    return np.reshape(np.array(logit_mu),(K,K)), np.reshape(np.array(logit_sigma),(K,K))\n",
    "    \n",
    "\n",
    "#Rowwise normalization\n",
    "def rowwise_softmax(psi):\n",
    "    \"\"\"Rowwise normalization\"\"\"\n",
    "    maxes = np.amax(psi, axis=1)\n",
    "    maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "    e = np.exp(psi - maxes)\n",
    "    dist = (e.T / np.sum(e, axis=1)).T\n",
    "    return dist\n",
    "\n",
    "def columnwise_softmax(psi):\n",
    "    \"\"\"Columnwise normalization\"\"\"\n",
    "    maxes = np.amax(psi, axis=0)\n",
    "    maxes = maxes.reshape(1, maxes.shape[0])\n",
    "    e = np.exp(psi - maxes)\n",
    "    dist = (e/ np.sum(e, axis=0))\n",
    "    return dist\n",
    "\n",
    "def log_prior(P, sigma_prior, K ):\n",
    "    \"\"\"Consider a product (coordinate-wise) of mixtures of two gaussians with std sigma_prior and centers at 0 and 1)\"\"\"\n",
    "    mixture_centers = [0 , 1]\n",
    "    differences = np.tile(np.reshape(P, (K,K,1)), (1, 1, 2)) - mixture_centers\n",
    "    n = K * K \n",
    "\n",
    "    return np.sum(logsumexp(- (differences ** 2 / (2 * sigma_prior )**2), axis = 2)) - n/2 *np.log( 2* np.pi) \\\n",
    "    - n* np.log(2) - n*np.log(sigma_prior)\n",
    "\n",
    "def log_prob(P, log_M, N):\n",
    "    \"\"\"\n",
    "    M represents the real transition probabilities  (inferred from a text) of letter\n",
    "    N is matrix containing the observed transitions from i-ths symbol to j-th symbol.\n",
    "\n",
    "    p is a Permutation matrix, p[i,j] = 1 if the i-the symbol is ciphered to the j-th symbol\"\"\"\n",
    "\n",
    "    \n",
    "    return np.trace(np.dot(log_M.T, np.dot(P, np.dot(N, P.T))))\n",
    "\n",
    "\n",
    "def sample_to_pi(sample, temp):\n",
    "    \n",
    "    return sample * temp + (1 - temp) * round_to_perm(sample) \n",
    "    \n",
    "\n",
    "def get_samples(params, noise,  temp, limits, M):\n",
    "    \"\"\" obtains a reparameterized variable (sample) and a one closer to the center of the voronoi cell\"\"\"\n",
    "    K = noise.shape[1]\n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params, K, M)\n",
    "    \n",
    "    #Do ten iterations of sinkhorn propagation (I've seen with 3 we also do a good job)\n",
    "    mu = np.exp(logit_mu*M)\n",
    "    for j in range(10):\n",
    "        \n",
    "        mu = rowwise_softmax(np.log(mu*M))\n",
    "        mu = columnwise_softmax(np.log(mu*M))\n",
    "    \n",
    "    sigma = limits[0] + (limits[1] - limits[0]) * logistic(logit_sigma)\n",
    "    sample = noise * sigma + mu\n",
    "    \n",
    "    return (sample, np.array([sample_to_pi(sample[i,:,:], temp) for i in range(sample.shape[0])]))\n",
    "    \n",
    "def log_density_gaussian(params, temp, limits, K):\n",
    "    \n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params,  K, M)\n",
    "    sigma = limits[0] + (limits[1] - limits[0]) * logistic(logit_sigma)\n",
    "    log_sigma =np.log(sigma)\n",
    "    entropy = 0.5 * log_sigma.size * (1.0 + np.log(2 * np.pi)) + np.sum(log_sigma)\n",
    "    \n",
    "    return entropy + K *(K) * np.log(temp)\n",
    "\n",
    "def variational_objective(params, t,  M, sigma_prior, limits_sigma):\n",
    "    \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "    K = M.shape[0]\n",
    "    \n",
    "    noise = npr.randn(num_mcmc_samples, K, K)\n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params,  K, M)\n",
    "    \n",
    "    (samples, P_samples) = get_samples(params, noise, temperature(t), limits_sigma, M)\n",
    "    elbo = 0\n",
    "    \n",
    "    for P in P_samples:\n",
    "        elbo = elbo + log_prob(P,log_M, N) / num_mcmc_samples \n",
    "        elbo = elbo + log_prior(P, sigma_prior, K ) / num_mcmc_samples\n",
    "    elbo = elbo + log_density_gaussian(params, temperature(t), limits_sigma, K)\n",
    "        \n",
    "    return [-elbo, log_prob(P_samples[0],log_M,N), log_prior(P, sigma_prior, K ), log_density_gaussian(params, temperature(t), limits_sigma, K)]\n",
    " \n",
    "\n",
    "def callback(params, t, g, perline=10):\n",
    "    \"\"\" Display something every perline iterations\"\"\"\n",
    "    K=27\n",
    "    num_mcmc_samples = 1\n",
    "    elbos.append(variational_objective(params, t, M, sigma_prior, limits_sigma))\n",
    "    params_all.append(params)\n",
    "    \n",
    "    \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "    def n_correct(P1,P2):\n",
    "        return P1.shape[0]- np.sum(np.abs(P1-P2))/2.0\n",
    "\n",
    "    def perm_to_P(perm):\n",
    "        K=len(perm)\n",
    "        P = np.zeros((K,K))\n",
    "        P[range(K),perm] = 1 \n",
    "        return P\n",
    "    \n",
    "    if (t % perline) == 0:\n",
    "        sys.stdout.write('. [Iter {0}/{1}] VLB: {2:.1f}\\n'.format(t, num_adam_iters, -elbos[-1][0]))\n",
    "        print 'Different components of elbo' + ' ' + str(elbos[-1][1]) + ' ' +  str(elbos[-1][2]) + ' ' +  str(elbos[-1][3])\n",
    "        \n",
    "        noise = npr.randn(num_mcmc_samples,K, K)\n",
    "        (sample, P_samples) = get_samples(params, noise, temperature(t), limits_sigma, M)\n",
    "        perm_inferred = linear_sum_assignment(-P_samples[0])\n",
    "        P_inf =perm_to_P(np.array(perm_inferred[1]))\n",
    "          if t >0:\n",
    "            print 'Currently decoded text: ' + decipher_text(alphabet_list,np.array(perm_inferred[1]),ciphered_text)[:143]\n",
    "        else:\n",
    "            print 'Ciphered text: ' + decipher_text(alphabet_list,np.array(perm_inferred[1]),ciphered_text)[:143]\n",
    "        print 'For a random sample the number of correctly guessed characters was ' +str(n_correct(P_true,P_inf))\n",
    "        print 'Log probability of non-rounded sample is ' + str(log_prob(P_samples[0],log_M,N))\n",
    "        print 'Log probability of rounded sample is ' + str(log_prob(P_inf,log_M,N))\n",
    "        print 'Log probability of solution is ' + str(log_prob(P_true,log_M,N))\n",
    "      \n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational inference for matching...\n",
      "Initializing with MAP estimate\n",
      ". [Iter 0/1000] VLB: 16088.8\n",
      "Different components of elbo 18763.3601518 -2155.42485927 -519.089463801\n",
      "For a random sample the number of correctly guessed characters was 0.0\n",
      "log probability of non-rounded sample is-6973.83146065\n",
      "Log probability of rounded sample is 11811.4166193\n",
      "Log probability of solution is 17358.4371991\n",
      "Ciphered text: NDECMHXYJEBNXYE AHDEGHJD ERJCCGECGE AYEGJYYENVSERJCRYJENO HCVECGEAHDEMWVBDE AYERN OATCJUEOCXYJMY ETAHOAETNDEONJYMYDDMLEGMWVBECXYJE AYEHJCVEKYSD\n",
      ".......... [Iter 10/1000] VLB: 4817.7\n",
      "Different components of elbo 7433.67065993 -2144.85947108 -471.087737698\n",
      "For a random sample the number of correctly guessed characters was 1.0\n",
      "log probability of non-rounded sample is-3097.37234709\n",
      "Log probability of rounded sample is 7823.91366282\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: MRBGXVHWKBPMHWBNAVRBFVKRNBCKGGFBGFBNAWBFKWWBMYTBCKGCWKBMLNVGYBGFBAVRBXIYPRBNAWBCMNLADGKJBLGHWKXWNBDAVLABDMRBLMKWXWRRXUBFXIYPBGHWKBNAWBVKGYBEWTR\n",
      ".......... [Iter 20/1000] VLB: 2515.0\n",
      "Different components of elbo 5291.67675398 -2351.1549446 -425.496382616\n",
      "For a random sample the number of correctly guessed characters was 2.0\n",
      "log probability of non-rounded sample is-2071.80623813\n",
      "Log probability of rounded sample is 10456.9955686\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: MXALUGCQEAPMCQA NGXARGEX AFELLRALRA NQAREQQAMBOAFELFQEAMV GLBALRANGXAUDBPXA NQAFM VNWLEIAVLCQEUQ AWNGVNAWMXAVMEQUQXXUHARUDBPALCQEA NQAGELBAKQOX\n",
      ".......... [Iter 30/1000] VLB: 73285.9\n",
      "Different components of elbo 76070.9346966 -2400.05324261 -385.016795723\n",
      "For a random sample the number of correctly guessed characters was 0.0\n",
      "log probability of non-rounded sample is-6236.52815929\n",
      "Log probability of rounded sample is 8399.28441534\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: NDCIXQHBPCLNHBCUAQDCMQPDUCOPIIMCIMCUABCMPBBCNFKCOPIOBPCNWUQIFCIMCAQDCXZFLDCUABCONUWATIPJCWIHBPXBUCTAQWACTNDCWNPBXBDDXECMXZFLCIHBPCUABCQPIFCYBKD\n",
      ".......... [Iter 40/1000] VLB: -5488.1\n",
      "Different components of elbo -2937.8583946 -2202.24024071 -347.982131592\n",
      "For a random sample the number of correctly guessed characters was 0.0\n",
      "log probability of non-rounded sample is5897.7426485\n",
      "Log probability of rounded sample is 8617.64044996\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: TORXWJDYNRPTDYRLKJOREJNOLRCNXXERXERLKYRENYYRTFVRCNXCYNRTBLJXFRXERKJORWIFPORLKYRCTLBKGXNMRBXDYNWYLRGKJBKRGTORBTNYWYOOWHREWIFPRXDYNRLKYRJNXFRSYVO\n",
      ".......... [Iter 50/1000] VLB: -4886.1\n",
      "Different components of elbo -2472.10256944 -2099.95360353 -314.090405591\n",
      "For a random sample the number of correctly guessed characters was 2.0\n",
      "log probability of non-rounded sample is33487.0328386\n",
      "Log probability of rounded sample is 8917.1023743\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: OSILMRTQHIDOTQIYVRSIURHSYIZHLLUILUIYVQIUHQQIOBNIZHLZQHIOPYRLBILUIVRSIMXBDSIYVQIZOYPVALHCIPLTQHMQYIAVRPVIAOSIPOHQMQSSMFIUMXBDILTQHIYVQIRHLBIWQNS\n",
      ".......... [Iter 60/1000] VLB: 11449.6\n",
      "Different components of elbo 13793.9384016 -2059.88275926 -284.457555496\n",
      "For a random sample the number of correctly guessed characters was 3.0\n",
      "log probability of non-rounded sample is12467.224197\n",
      "Log probability of rounded sample is 11318.2724085\n",
      "Log probability of solution is 17358.4371991\n",
      "Currently decoded text: QGALVOZHJATQZHADSOGABOJGDAYJLLBALBADSHABJHHAQI AYJLYHJAQXDOLIALBASOGAVUITGADSHAYQDXSWLJKAXLZHJVHDAWSOXSAWQGAXQJHVHGGVNABVUITALZHJADSHAOJLIARH G\n",
      "....."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9b04953ed3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mparams_all\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mvariational_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_var_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_adam_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/optimizers.pyc\u001b[0m in \u001b[0;36madam\u001b[0;34m(grad, init_params, callback, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m      \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m  \u001b[0;31m# First  moment estimate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/util.pyc\u001b[0m in \u001b[0;36mflattened_func\u001b[0;34m(flattened_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflattened_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mflattened_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflattened_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/convenience_wrappers.pyc\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to_same_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output seems independent of input.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node, start_node)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcur_outgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mvsum\u001b[0;34m(vspace, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive_vsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprogenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogenitors\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogenitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogenitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36mprimitive_vsum\u001b[0;34m(vspace, *args)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprimitive_vsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSparseObject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/numpy/numpy_extra.pyc\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cybele/GIT/autograd/autograd/core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mprogenitors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Global parameters\n",
    "npr.seed(0)\n",
    "\n",
    "num_adam_iters = 1000\n",
    "num_mcmc_samples = 1\n",
    "limits_sigma =[0.00,1]\n",
    "sigma_prior =0.1 #variance of mixture of gaussians prior\n",
    "\n",
    "#Now encode soft contrains (P[i,j] = 0) using a mask \"M\". This matrix has one entries and 0 if P[i,j] =0 \n",
    "#(a very small number here as we take logs). Notice I am selecting 2 soft contrains per character\n",
    "M = np.ones((K,K))\n",
    "listchar = npr.choice(K, K,replace= False)\n",
    "for m in listchar:\n",
    "    \n",
    "    i = np.where(P_true[m,:] ==1)[0]\n",
    "    \n",
    "    random = npr.choice(K, 2, replace = False)\n",
    "    M[m, [j for j in random if j not in [i]]] = 1e-8\n",
    "    \n",
    "def temperature(i): \n",
    "    \"\"\" for now lets keep the temperature fixed \"\"\"\n",
    "    tau0=0.75\n",
    "    MIN_TEMP = 0.75\n",
    "    ANNEAL_RATE = 0.1\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    return np_temp\n",
    "\n",
    "indexes = np.where(M.flatten() ==1)[0] #find indexes of efective parameters\n",
    "n_params = len(indexes)\n",
    "\n",
    "init_mean = -10*np.ones(n_params)\n",
    "init_logit_std = -5*npr.randn(n_params)\n",
    "init_var_params = np.concatenate([init_mean, init_logit_std])\n",
    "\n",
    "\n",
    "print(\"Variational inference for matching...\")\n",
    "print(\"Initializing with MAP estimate\")\n",
    "\n",
    "elbos=[]\n",
    "# SGD with Adam\n",
    "\n",
    "var_objective = lambda x,t: variational_objective(x, t , M, sigma_prior, limits_sigma)[0]\n",
    "gradient = grad(var_objective)\n",
    "elbos = []\n",
    "params_all =[]\n",
    "\n",
    "variational_params = adam(gradient, init_var_params, step_size=0.05, num_iters=num_adam_iters, callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is for the analysis of solutions, not relevant for now (it plots the evolution of mu, variances and elbos, etc)\n",
    "limits_sigma =[0.00,1]\n",
    "noise = npr.randn(5,K, K)\n",
    "print temperature(100)\n",
    "print num_mcmc_samples\n",
    "N_max = 1000\n",
    "mu_all =np.zeros((N_max,(K) * K ))\n",
    "sigma_all =np.zeros((N_max, (K ) * K ))\n",
    "(sample, P_samples) = get_samples(params_all[-1], noise, temperature(20), limits_sigma, M)\n",
    "\n",
    "for i in range(N_max):\n",
    "    \n",
    "    logit_mu, logit_sigma = unpack_params_sparse(params_all[i], K , M)\n",
    "    \n",
    "    #mu = rowwise_softmax(np.hstack((logit_mu, np.zeros((logit_mu.shape[0],1)))))\n",
    "    mu = np.exp(logit_mu)\n",
    "    for j in range(10):\n",
    "        mu = rowwise_softmax(np.log(mu))\n",
    "        mu = columnwise_softmax(np.log(mu))\n",
    "        \n",
    "    sigma = limits[1, 0] + (limits[1, 1] - limits[1, 0]) * logistic(logit_sigma)\n",
    "    mu_all[i,:] = mu.flatten()\n",
    "    sigma_all[i,:] = sigma.flatten()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(221)\n",
    "plt.plot(mu_all)\n",
    "plt.subplot(222)\n",
    "plt.plot(sigma_all)\n",
    "plt.subplot(223)\n",
    "plt.plot(np.array([elbos[i][-1] for i in range(N_max)]))\n",
    "plt.subplot(224)\n",
    "plt.plot(np.reshape(mu_all[-1], (K,K)))\n",
    "\n",
    "plt.figure()\n",
    "#print P_samples[0]\n",
    "plt.imshow(P_samples[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MCMC sampler, if want to compare\n",
    "def perm_to_P(perm):\n",
    "        K=len(perm)\n",
    "        P = np.zeros((K,K))\n",
    "        P[range(K),perm] = 1 \n",
    "        return P\n",
    "def P_to_perm(P):\n",
    "    perm =[]\n",
    "    for i in range(K):\n",
    "        perm.append(np.where(P[i,:] ==1)[0][0])\n",
    "    return perm\n",
    "\n",
    "def swap_perm(P,i,j):\n",
    "        perm = P_to_perm(P)\n",
    "        perm_aux = np.copy(perm)\n",
    "        perm[i] = perm_aux[j]\n",
    "        perm[j] = perm_aux[i]\n",
    "        \n",
    "        return perm_to_P(perm)\n",
    "def MCMC_solver(log_M,N,N_iter_MCMC_solver):\n",
    "    K=log_M.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    perm_initial = np.random.choice(range(K),K, replace = False)\n",
    "    P_initial = perm_to_P(perm_initial)\n",
    "\n",
    "    P = P_initial\n",
    "    log_prob_current = log_prob(P,log_M,N,0)\n",
    "    for i in range(N_iter_MCMC_solver):\n",
    "        if  i % 100 ==0:\n",
    "            print 'Iteration ' + str(i)\n",
    "        indexes = np.random.choice(range(K), 2, replace = False)\n",
    "        P_prop = swap_perm(P, indexes[0], indexes[1])\n",
    "        log_prob_prop = log_prob(P_prop, log_M, N, 0)\n",
    "        if(log_prob_prop > log_prob_current):\n",
    "            P = P_prop\n",
    "            log_prob_current  = log_prob_prop\n",
    "        else:\n",
    "            p = np.exp(log_prob_prop - log_prob_current)\n",
    "            if(np.random.uniform(0, 1) < p):\n",
    "                P = P_prop\n",
    "                log_prob_current  = log_prob_prop\n",
    "    perm = []\n",
    "    #for i in range(K):\n",
    "     #   perm.append(np.where(P[i,:] ==1)[0][0])\n",
    "    #return np.array(perm)\n",
    "    return np.array(P_to_perm(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_iter_MCMC_solver = 1000\n",
    "perm_MCMC = MCMC_solver(log_M,N,N_iter_MCMC_solver)\n",
    "print decipher_text(alphabet_list,perm_MCMC,ciphered_text)\n",
    "print log_prob(np.ones((27,27))/27, log_M,N,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
